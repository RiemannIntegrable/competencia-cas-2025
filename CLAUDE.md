# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

# Competencia de Casos CAS y ACTEX 2025
## Modelo Predictivo para Tarificaci√≥n de Seguros de Inquilinos

## üéØ Contexto del Proyecto

### Descripci√≥n General
Estamos participando en la **Competencia de Casos CAS y ACTEX 2025**, desarrollando un modelo predictivo para **Sigma Seguros**, una aseguradora de l√≠neas personales que busca optimizar su tarificaci√≥n en el mercado de seguros para inquilinos residenciales, espec√≠ficamente para estudiantes universitarios con su producto "P√≥liza para Dormitorios".

### Objetivo Principal
Desarrollar un **modelo predictivo actuarialmente s√≥lido** que utilice tanto el historial de siniestros como los datos demogr√°ficos para determinar una **prima pura de riesgo** individualizada para cada asegurado, reemplazando el actual sistema de prima √∫nica para todos.

### Responsables del Proyecto

- Estudiantes de Maestr√≠a en Actuar√≠a y Finanzas (UNAL)

**Jos√© Miguel Acu√±a Hern√°ndez**
**Guillermo Murillo Tirado**
**Yeferson Fabian Rubio**
**Sergio Diaz Vera**
**Andres Steven Puertas Londo√±o**

- Docente del departamento de Estadistica (UNAL)

**Mario Enrique Arrieta**

## üìä Estructura de Datos

### Dataset Principal
- **Archivo**: `data/input/Competencia de Casos CAS y ACTEX - Datos - datos.csv`
- **Registros**: 10,000 p√≥lizas con diferentes grados de riesgo
- **Per√≠odo**: Un a√±o de siniestralidad hist√≥rica

### Variables Disponibles

#### Variables Demogr√°ficas
- `estudiante_id`: Identificador √∫nico
- `nombre`: Nombre del asegurado
- `a√±o_cursado`: 1er a√±o, 2do a√±o, 3er a√±o, 4to a√±o, posgrado
- `estudios_area`: Administraci√≥n, Ciencias, Humanidades, Otro
- `calif_promedio`: Promedio acad√©mico (escala 0-10)
- `genero`: Masculino, Femenino, Otro, No respuesta
- `2_o_mas_inquilinos`: Si/No - M√∫ltiples inquilinos en la vivienda

#### Variables de Ubicaci√≥n
- `en_campus`: Dentro de campus / Fuera de campus
- `distancia_al_campus`: Distancia en unidades (0 si est√° dentro del campus)

#### Variables de Riesgo
- `extintor_incendios`: Si/No - Presencia de extintor
- `clase_suscripcion`: Clase1, Clase2, Clase3 - Asignada por departamento de suscripci√≥n
- `retencion`: entrenamiento/validacion - Divisi√≥n del dataset

#### Variables de Siniestralidad (4 coberturas)
1. **Contenidos** (l√≠mite USD 10,000)
   - `Contenidos_siniestros_num`: N√∫mero de siniestros
   - `Contenidos_siniestros_monto`: Monto total de siniestros

2. **Gastos Adicionales de Vivienda** (l√≠mite USD 20,000)
   - `Gastos_Adicionales_siniestros_num`: N√∫mero de siniestros
   - `Gastos_Adicionales_siniestros_monto`: Monto total de siniestros

3. **Responsabilidad Civil** (l√≠mite USD 300,000)
   - `Resp_Civil_siniestros_num`: N√∫mero de siniestros
   - `Resp_Civil_siniestros_monto`: Monto total de siniestros

4. **Gastos M√©dicos RC** (l√≠mite USD 150,000)
   - `Gastos_Medicos_RC_siniestros_num`: N√∫mero de siniestros
   - `Gastos_Medicos_RC_siniestros_monto`: Monto total de siniestros

### Divisi√≥n de Datos
- **Entrenamiento**: Registros con `retencion = "entrenamiento"` - Incluyen todas las variables
- **Validaci√≥n**: Registros con `retencion = "validacion"` - Sin informaci√≥n de siniestralidad (holdout)

## üéØ M√©tricas de Evaluaci√≥n

### Primera Fase - Clasificaci√≥n
Los equipos ser√°n rankeados por el promedio de dos m√©tricas:

1. **Error Absoluto Medio (EAM)**
   - F√≥rmula: `EAM = (1/N) * Œ£|Y_k - ≈∂_k|`
   - Objetivo: **Minimizar** (menor es mejor)

2. **Coeficiente de Gini**
   - Mide la capacidad del modelo para diferenciar riesgos
   - Objetivo: **Maximizar** (mayor es mejor)
   - Archivo de referencia: `gini_coef_ilustracion.xlsm`

**Ranking final**: Promedio de las posiciones en ambas m√©tricas
**Clasificados**: Los 5 mejores equipos pasan a la segunda fase

### Variable Objetivo
**Monto total de siniestros** para la suma de las cuatro coberturas

## üìã Entregables de la Competencia

1. **Archivo de predicciones**:
   - Formato: `Competencia de Casos CAS y ACTEX - Hoja de Predicciones.xlsx`
   - Una predicci√≥n por cada registro de validaci√≥n
   - Columna: `prediccion monto total siniestro`

2. **Documento explicativo** (1 p√°gina):
   - Proceso de modelaci√≥n
   - Modelos considerados
   - Justificaci√≥n del modelo seleccionado

### Segunda Fase (Final)
Presentaci√≥n ante jueces abordando:
- An√°lisis de datos y transformaciones
- T√©cnicas de modelaci√≥n evaluadas
- Validaci√≥n y evidencia del modelo
- Consideraciones de negocio
- Estrategia de tarificaci√≥n a mediano plazo

## üîß Metodolog√≠a Recomendada

### Modelos Sugeridos
- **GLMs (Modelos Lineales Generalizados)**: Est√°ndar de la industria
- **√Årboles de Decisi√≥n**: Para capturar interacciones no lineales
- **Gradient Boosting Models**: Para optimizaci√≥n de predicciones
- **Ensambles**: Combinaci√≥n de m√∫ltiples modelos

### Consideraciones T√©cnicas

#### Estructura de Prima de Riesgo
1. Definir clase base de referencia
2. Calcular prima base
3. Aplicar factores multiplicativos relativos: `prima_riesgo = prima_base √ó (1 ¬± X%)`

#### Decisiones de Modelaci√≥n
- ¬øUn modelo global o modelos separados por cobertura?
- ¬øModelar frecuencia y severidad por separado o p√©rdida agregada?
- ¬øC√≥mo manejar el desbalance de clases (muchos ceros en siniestros)?

### Proceso CRISP-DM Recomendado
1. **Comprensi√≥n del Negocio**: Contexto de seguros para estudiantes
2. **Comprensi√≥n de Datos**: EDA exhaustivo de las 10,000 p√≥lizas
3. **Preparaci√≥n de Datos**:
   - Tratamiento de valores faltantes
   - Codificaci√≥n de variables categ√≥ricas
   - Feature engineering
4. **Modelaci√≥n**: Desarrollo y comparaci√≥n de modelos
5. **Evaluaci√≥n**: M√©tricas EAM y Gini
6. **Despliegue**: Predicciones finales

## üìÅ Estructura del Proyecto

```
competencia_cas/
‚îÇ
‚îú‚îÄ‚îÄ CLAUDE.md                    # Este archivo - Contexto del proyecto
‚îú‚îÄ‚îÄ README.md                    # Documentaci√≥n general
‚îú‚îÄ‚îÄ LICENSE                      # Licencia del proyecto
‚îú‚îÄ‚îÄ environmet.yml               # Configuraci√≥n del entorno conda
‚îÇ
‚îú‚îÄ‚îÄ .claude/                     # Configuraci√≥n de Claude Code
‚îÇ   ‚îî‚îÄ‚îÄ settings.local.json
‚îÇ
‚îú‚îÄ‚îÄ context/                     # Contexto detallado para Claude Code
‚îÇ   ‚îú‚îÄ‚îÄ actuarial-context.md     # Fundamentos actuariales y de tarificaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ methodology.md           # Metodolog√≠a CRISP-DM y t√©cnicas
‚îÇ   ‚îú‚îÄ‚îÄ project-overview.md      # Vista general del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ standards.md             # Est√°ndares de c√≥digo y documentaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/                   # Datos originales de la competencia
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Competencia de Casos CAS y ACTEX - Descripci√≥n.pdf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Competencia de Casos CAS y ACTEX - Datos - datos.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Competencia de Casos CAS y ACTEX - Hoja de Predicciones.xlsx - Predicciones.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [1-4].jpg            # Diapositivas de presentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # Datos procesados y transformados
‚îÇ   ‚îî‚îÄ‚îÄ output/                  # Predicciones generadas
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Jupyter notebooks para an√°lisis
‚îÇ   ‚îî‚îÄ‚îÄ exploracion.ipynb        # An√°lisis exploratorio inicial
‚îÇ
‚îú‚îÄ‚îÄ src/                         # C√≥digo fuente Python/R
‚îÇ   ‚îú‚îÄ‚îÄ data/                    # M√≥dulos de procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ test/                    # Tests unitarios
‚îÇ   ‚îî‚îÄ‚îÄ utils/                   # Funciones utilitarias
‚îÇ
‚îú‚îÄ‚îÄ models/                      # Modelos entrenados serializados
‚îÇ
‚îú‚îÄ‚îÄ report/                      # Documentaci√≥n LaTeX del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ main.tex                 # Documento principal
‚îÇ   ‚îú‚îÄ‚îÄ referencias.bib          # Referencias bibliogr√°ficas
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Configuraci√≥n LaTeX
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands.tex         # Comandos personalizados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc_style.tex        # Estilos del documento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ packages.tex         # Paquetes LaTeX
‚îÇ   ‚îú‚îÄ‚îÄ content/                 # Contenido del reporte
‚îÇ   ‚îî‚îÄ‚îÄ images/                  # Im√°genes para el reporte
‚îÇ
‚îú‚îÄ‚îÄ output/                      # Salidas finales y entregables
‚îÇ
‚îî‚îÄ‚îÄ images/                      # Gr√°ficos y visualizaciones del proyecto

```

## üìö Archivos de Contexto Detallado

Para informaci√≥n m√°s espec√≠fica, consultar:

- **[`context/project-overview.md`](context/project-overview.md)**: Vista general resumida del proyecto y equipo
- **[`context/actuarial-context.md`](context/actuarial-context.md)**: Conceptos actuariales, coberturas y m√©tricas
- **[`context/methodology.md`](context/methodology.md)**: Framework CRISP-DM y plan de trabajo
- **[`context/standards.md`](context/standards.md)**: Est√°ndares de c√≥digo y documentaci√≥n

---

## üõ†Ô∏è Configuraci√≥n del Entorno

### Entornos Conda

El proyecto usa dos entornos conda separados:

**Python (Principal)**:
```bash
conda env create -f environmet_python.yml
conda activate competencia_cas_python
```

**R (An√°lisis complementario)**:
```bash
conda env create -f environment_r.yml
conda activate competencia_cas_r
```

### Jupyter Notebooks

Todos los notebooks est√°n en `notebooks/`. Para iniciar Jupyter:
```bash
jupyter notebook notebooks/
# o
jupyter lab
```

## üìÇ Arquitectura de Datos

### Pipeline de Procesamiento

1. **Datos crudos**: `data/input/input.csv` (10,000 registros totales)
   - 7,999 registros de entrenamiento (`retencion == "entrenamiento"`)
   - 2,001 registros de validaci√≥n (`retencion == "validacion"`)

2. **Notebook de preprocesamiento**: `notebooks/tratamiento_data.ipynb`
   - Elimina columnas: `nombre`, `estudiante_id`, `clase_suscripcion`, `en_campus`, `retencion`
   - Genera 8 datasets procesados en `data/processed/`:

**Por cada cobertura se generan 2 datasets**:
- `{cobertura}_full.csv`: Todos los registros (para modelos de clasificaci√≥n)
- `{cobertura}_siniestrados.csv`: Solo registros con siniestros (para frecuencia/severidad)

**Coberturas**:
- `contenidos_*` (743 siniestrados de 7,999)
- `adicionales_*` (416 siniestrados de 7,999)
- `medicos_*` (183 siniestrados de 7,999)
- `rc_*` (67 siniestrados de 7,999)

3. **Datos de validaci√≥n final**: `data/input/test.csv`
   - 2,001 IDs de estudiantes para predicci√≥n final

## üî¨ Metodolog√≠a de Modelaci√≥n

### Estrategia de Modelaci√≥n por Cobertura

Para cada una de las 4 coberturas desarrollamos **3 modelos**:

1. **Clasificaci√≥n** (`clasificacion_{cobertura}.ipynb`):
   - Input: `{cobertura}_full.csv`
   - Target: Binario (siniestrado vs no siniestrado)
   - Optimizaci√≥n: F1-score (dataset muy desbalanceado)

2. **Frecuencia** (`frecuencia_{cobertura}.ipynb`):
   - Input: `{cobertura}_siniestrados.csv`
   - Target: `{Cobertura}_siniestros_num` (conteo)
   - Optimizaci√≥n: MAE

3. **Severidad** (`severidad_{cobertura}.ipynb`):
   - Input: `{cobertura}_siniestrados.csv`
   - Target: `{Cobertura}_siniestros_monto` (monto)
   - Optimizaci√≥n: MAE

### Pipeline Est√°ndar de Cada Notebook

**Fase 1: Preparaci√≥n y GLM Baseline**
1. Estandarizar variables num√©ricas (StandardScaler)
2. One-hot encoding de variables categ√≥ricas
3. Split train/test 80/20
4. GLM con selecci√≥n backward de variables
   - Clasificaci√≥n: Logistic Regression
   - Frecuencia: Poisson/Negative Binomial GLM
   - Severidad: Gamma/Inverse Gaussian GLM
5. Si un nivel de variable categ√≥rica es seleccionado, incluir **todos** los niveles
6. Con variables seleccionadas, correr LazyPredict para identificar top algoritmos

**Fase 2: Optimizaci√≥n de Top 5 Modelos**
1. Tomar los 5 mejores modelos de LazyPredict
2. GridSearchCV con validaci√≥n cruzada sobre train set
   - Par√°metros de regularizaci√≥n para evitar overfitting
   - M√©trica de optimizaci√≥n:
     - Regresi√≥n (frecuencia/severidad): `scoring='neg_mean_absolute_error'`
     - Clasificaci√≥n: `scoring='f1'`
3. Para clasificaci√≥n: optimizar threshold de probabilidad (no usar default 0.5)
4. Evaluar modelos optimizados en test set
5. Imprimir m√©tricas:
   - **Regresi√≥n**: MAE, GINI, R¬≤
   - **Clasificaci√≥n**: MAE, GINI, R¬≤, Accuracy

**Fase 3: Exportaci√≥n**
1. El modelo seleccionado se exporta a `models/` (se indicar√° cu√°l exportar)
2. Usar joblib o pickle para serializaci√≥n

### Notebooks Existentes

```
notebooks/
‚îú‚îÄ‚îÄ tratamiento_data.ipynb          # Preprocesamiento inicial
‚îú‚îÄ‚îÄ clasificacion_contenidos.ipynb  # Clasificaci√≥n Contenidos
‚îú‚îÄ‚îÄ frecuencia_contenidos.ipynb     # Frecuencia Contenidos
‚îú‚îÄ‚îÄ severidad_contenidos.ipynb      # Severidad Contenidos (modificado)
‚îú‚îÄ‚îÄ clasificacion_adicionales.ipynb # Clasificaci√≥n Gastos Adicionales
‚îú‚îÄ‚îÄ frecuencia_adicionales.ipynb    # Frecuencia Gastos Adicionales
‚îú‚îÄ‚îÄ severidad_adicionales.ipynb     # Severidad Gastos Adicionales
‚îú‚îÄ‚îÄ clasificacion_medicos.ipynb     # Clasificaci√≥n Gastos M√©dicos RC
‚îú‚îÄ‚îÄ frecuencia_medicos.ipynb        # Frecuencia Gastos M√©dicos RC
‚îú‚îÄ‚îÄ severidad_medicos.ipynb         # Severidad Gastos M√©dicos RC
‚îú‚îÄ‚îÄ clasificacion_rc.ipynb          # Clasificaci√≥n Resp. Civil
‚îú‚îÄ‚îÄ frecuencia_rc.ipynb             # Frecuencia Resp. Civil
‚îî‚îÄ‚îÄ severidad_rc.ipynb              # Severidad Resp. Civil
```

## üìä Variables del Dataset

### Variables Predictoras Disponibles

Despu√©s de eliminar ID y columnas redundantes, quedan:

- `a√±o_cursado`: 1er a√±o, 2do a√±o, 3er a√±o, 4to a√±o, posgrado (categ√≥rica)
- `estudios_area`: Administraci√≥n, Ciencias, Humanidades, Otro (categ√≥rica)
- `calif_promedio`: Promedio acad√©mico 0-10 (num√©rica)
- `genero`: Masculino, Femenino, Otro, No respuesta (categ√≥rica)
- `2_o_mas_inquilinos`: Si/No (categ√≥rica)
- `distancia_al_campus`: Distancia en unidades (num√©rica, 0 si dentro campus)
- `extintor_incendios`: Si/No (categ√≥rica)

### Variables Target por Tipo de Modelo

| Cobertura | Clasificaci√≥n | Frecuencia | Severidad |
|-----------|--------------|------------|-----------|
| Contenidos | `Contenidos_siniestros_num > 0` | `Contenidos_siniestros_num` | `Contenidos_siniestros_monto` |
| Gastos Adicionales | `Gastos_Adicionales_siniestros_num > 0` | `Gastos_Adicionales_siniestros_num` | `Gastos_Adicionales_siniestros_monto` |
| Resp. Civil | `Resp_Civil_siniestros_num > 0` | `Resp_Civil_siniestros_num` | `Resp_Civil_siniestros_monto` |
| Gastos M√©dicos RC | `Gastos_Medicos_RC_siniestros_num > 0` | `Gastos_Medicos_RC_siniestros_num` | `Gastos_Medicos_RC_siniestros_monto` |

## üéØ Consideraciones Actuariales Clave

### Desbalance de Clases

Los datasets est√°n **muy desbalanceados**:
- Contenidos: 9.3% siniestros (743/7999)
- Gastos Adicionales: 5.2% siniestros (416/7999)
- Gastos M√©dicos: 2.3% siniestros (183/7999)
- Resp. Civil: 0.8% siniestros (67/7999)

**Implicaciones**:
- Usar F1-score (no accuracy) para clasificaci√≥n
- Considerar t√©cnicas de balanceo si es necesario (SMOTE, class_weight)
- Optimizar threshold de clasificaci√≥n para balance precision/recall

### Familias de Distribuci√≥n para GLMs

**Clasificaci√≥n**: Binomial (link=logit)
**Frecuencia**: Poisson o Negative Binomial (sobredispersi√≥n)
**Severidad**: Gamma (montos positivos, asim√©tricos) o Inverse Gaussian

## üöÄ Comandos Comunes

### Git
```bash
# Ver estado
git status

# Commit de cambios
git add .
git commit -m "Descripci√≥n del cambio"
git push
```

### Gesti√≥n de Modelos
```bash
# Los modelos se guardan en models/
ls -lh models/

# Exportar modelo desde notebook:
# import joblib
# joblib.dump(modelo, '../models/nombre_modelo.pkl')
```

---

*√öltima actualizaci√≥n: 2025-10-10*