{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Modelo de Frecuencia - Contenidos\n",
    "\n",
    "## Objetivo\n",
    "Predecir la **frecuencia de siniestros** (número de siniestros) en la cobertura de Contenidos para asegurados que ya siniestrados (clasificación multinomial).\n",
    "\n",
    "## Pipeline\n",
    "1. **Fase 1**: Preprocesamiento + Multinomial Logit + Selección Backward + LazyPredict\n",
    "\n",
    "**Dataset**: Solo registros siniestrados de Contenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Intentar importar XGBoost y LightGBM (opcionales)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print(\"⚠ XGBoost no disponible\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    HAS_LGBM = True\n",
    "except ImportError:\n",
    "    HAS_LGBM = False\n",
    "    print(\"⚠ LightGBM no disponible\")\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# LazyPredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# GLM Multinomial Logit\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original: (743, 15)\n",
      "\n",
      "Columnas: ['año_cursado', 'estudios_area', 'calif_promedio', '2_o_mas_inquilinos', 'distancia_al_campus', 'genero', 'extintor_incendios', 'Gastos_Adicionales_siniestros_num', 'Gastos_Adicionales_siniestros_monto', 'Gastos_Medicos_RC_siniestros_num', 'Gastos_Medicos_RC_siniestros_monto', 'Resp_Civil_siniestros_num', 'Resp_Civil_siniestros_monto', 'Contenidos_siniestros_num', 'Contenidos_siniestros_monto']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año_cursado</th>\n",
       "      <th>estudios_area</th>\n",
       "      <th>calif_promedio</th>\n",
       "      <th>2_o_mas_inquilinos</th>\n",
       "      <th>distancia_al_campus</th>\n",
       "      <th>genero</th>\n",
       "      <th>extintor_incendios</th>\n",
       "      <th>Gastos_Adicionales_siniestros_num</th>\n",
       "      <th>Gastos_Adicionales_siniestros_monto</th>\n",
       "      <th>Gastos_Medicos_RC_siniestros_num</th>\n",
       "      <th>Gastos_Medicos_RC_siniestros_monto</th>\n",
       "      <th>Resp_Civil_siniestros_num</th>\n",
       "      <th>Resp_Civil_siniestros_monto</th>\n",
       "      <th>Contenidos_siniestros_num</th>\n",
       "      <th>Contenidos_siniestros_monto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2do año</td>\n",
       "      <td>Otro</td>\n",
       "      <td>2.45</td>\n",
       "      <td>No</td>\n",
       "      <td>10.08</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>990.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4to año</td>\n",
       "      <td>Ciencias</td>\n",
       "      <td>4.69</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1172.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2do año</td>\n",
       "      <td>Administracion</td>\n",
       "      <td>6.46</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2106.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3er año</td>\n",
       "      <td>Ciencias</td>\n",
       "      <td>8.02</td>\n",
       "      <td>Si</td>\n",
       "      <td>9.15</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1433.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4to año</td>\n",
       "      <td>Ciencias</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  año_cursado   estudios_area  calif_promedio 2_o_mas_inquilinos  \\\n",
       "0     2do año            Otro            2.45                 No   \n",
       "1     4to año        Ciencias            4.69                 Si   \n",
       "2     2do año  Administracion            6.46                 Si   \n",
       "3     3er año        Ciencias            8.02                 Si   \n",
       "4     4to año        Ciencias            8.10                 Si   \n",
       "\n",
       "   distancia_al_campus     genero extintor_incendios  \\\n",
       "0                10.08   Femenino                 Si   \n",
       "1                 0.00  Masculino                 Si   \n",
       "2                 0.00  Masculino                 Si   \n",
       "3                 9.15   Femenino                 Si   \n",
       "4                 0.00   Femenino                 No   \n",
       "\n",
       "   Gastos_Adicionales_siniestros_num  Gastos_Adicionales_siniestros_monto  \\\n",
       "0                               0.00                                 0.00   \n",
       "1                               0.00                                 0.00   \n",
       "2                               0.00                                 0.00   \n",
       "3                               0.00                                 0.00   \n",
       "4                               0.00                                 0.00   \n",
       "\n",
       "   Gastos_Medicos_RC_siniestros_num  Gastos_Medicos_RC_siniestros_monto  \\\n",
       "0                              0.00                                0.00   \n",
       "1                              0.00                                0.00   \n",
       "2                              0.00                                0.00   \n",
       "3                              0.00                                0.00   \n",
       "4                              0.00                                0.00   \n",
       "\n",
       "   Resp_Civil_siniestros_num  Resp_Civil_siniestros_monto  \\\n",
       "0                       0.00                         0.00   \n",
       "1                       0.00                         0.00   \n",
       "2                       0.00                         0.00   \n",
       "3                       0.00                         0.00   \n",
       "4                       0.00                         0.00   \n",
       "\n",
       "   Contenidos_siniestros_num  Contenidos_siniestros_monto  \n",
       "0                       1.00                       990.60  \n",
       "1                       1.00                      1172.94  \n",
       "2                       1.00                      2106.47  \n",
       "3                       1.00                      1433.56  \n",
       "4                       1.00                       500.61  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos de estudiantes siniestrados\n",
    "df = pd.read_csv(\"../data/processed/contenidos_siniestrados.csv\")\n",
    "\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "print(f\"\\nColumnas: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset preparado: (743, 8)\n",
      "\n",
      "Distribución variable objetivo (frecuencia):\n",
      "Contenidos_siniestros_num\n",
      "1.00    702\n",
      "2.00     38\n",
      "3.00      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estadísticas de frecuencia:\n",
      "count   743.00\n",
      "mean      1.06\n",
      "std       0.25\n",
      "min       1.00\n",
      "25%       1.00\n",
      "50%       1.00\n",
      "75%       1.00\n",
      "max       3.00\n",
      "Name: Contenidos_siniestros_num, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Eliminar columna de monto (no se usa en modelo de frecuencia)\n",
    "df = df.drop('Contenidos_siniestros_monto', axis=1)\n",
    "\n",
    "# Eliminar otras coberturas (no son features relevantes para este modelo)\n",
    "df = df.drop([\n",
    "    'Gastos_Medicos_RC_siniestros_num', 'Gastos_Medicos_RC_siniestros_monto',\n",
    "    'Resp_Civil_siniestros_num', 'Resp_Civil_siniestros_monto',\n",
    "    'Gastos_Adicionales_siniestros_num', 'Gastos_Adicionales_siniestros_monto'\n",
    "], axis=1)\n",
    "\n",
    "print(f\"\\nDataset preparado: {df.shape}\")\n",
    "print(f\"\\nDistribución variable objetivo (frecuencia):\")\n",
    "print(df['Contenidos_siniestros_num'].value_counts().sort_index())\n",
    "print(f\"\\nEstadísticas de frecuencia:\")\n",
    "print(df['Contenidos_siniestros_num'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Análisis Exploratorio Rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables numéricas: ['calif_promedio', 'distancia_al_campus']\n",
      "Variables categóricas: ['año_cursado', 'estudios_area', '2_o_mas_inquilinos', 'genero', 'extintor_incendios']\n",
      "\n",
      "Total features: 7\n",
      "\n",
      "Valores faltantes:\n",
      "año_cursado                  0\n",
      "estudios_area                0\n",
      "calif_promedio               0\n",
      "2_o_mas_inquilinos           0\n",
      "distancia_al_campus          0\n",
      "genero                       0\n",
      "extintor_incendios           0\n",
      "Contenidos_siniestros_num    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificar tipos de variables\n",
    "numeric_features = ['calif_promedio', 'distancia_al_campus']\n",
    "categorical_features = ['año_cursado', 'estudios_area', '2_o_mas_inquilinos', 'genero', 'extintor_incendios']\n",
    "\n",
    "print(\"Variables numéricas:\", numeric_features)\n",
    "print(\"Variables categóricas:\", categorical_features)\n",
    "print(f\"\\nTotal features: {len(numeric_features) + len(categorical_features)}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"\\nValores faltantes:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTADÍSTICAS DESCRIPTIVAS - FRECUENCIA PROMEDIO POR CATEGORÍA\n",
      "================================================================================\n",
      "\n",
      "año_cursado:\n",
      "             mean  count    sum\n",
      "año_cursado                    \n",
      "1er año      1.09    185 201.00\n",
      "2do año      1.04    183 191.00\n",
      "3er año      1.07    171 183.00\n",
      "4to año      1.03    144 149.00\n",
      "posgrado     1.05     60  63.00\n",
      "\n",
      "estudios_area:\n",
      "                mean  count    sum\n",
      "estudios_area                     \n",
      "Administracion  1.06    208 221.00\n",
      "Ciencias        1.03    188 193.00\n",
      "Humanidades     1.05    171 179.00\n",
      "Otro            1.10    176 194.00\n",
      "\n",
      "2_o_mas_inquilinos:\n",
      "                    mean  count    sum\n",
      "2_o_mas_inquilinos                    \n",
      "No                  1.04    490 512.00\n",
      "Si                  1.09    253 275.00\n",
      "\n",
      "genero:\n",
      "              mean  count    sum\n",
      "genero                          \n",
      "Femenino      1.09    323 351.00\n",
      "Masculino     1.04    347 360.00\n",
      "No respuesta  1.03     29  30.00\n",
      "Otro          1.04     44  46.00\n",
      "\n",
      "extintor_incendios:\n",
      "                    mean  count    sum\n",
      "extintor_incendios                    \n",
      "No                  1.09    209 227.00\n",
      "Si                  1.05    534 560.00\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas descriptivas - Frecuencia promedio por categoría\n",
    "print(\"=\" * 80)\n",
    "print(\"ESTADÍSTICAS DESCRIPTIVAS - FRECUENCIA PROMEDIO POR CATEGORÍA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for var in categorical_features:\n",
    "    print(f\"\\n{var}:\")\n",
    "    tabla = df.groupby(var)['Contenidos_siniestros_num'].agg(['mean', 'count', 'sum'])\n",
    "    print(tabla.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento y Split de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (594, 7) | Frecuencia promedio: 1.0606\n",
      "Test set:  (149, 7) | Frecuencia promedio: 1.0537\n",
      "\n",
      "Distribución train:\n",
      "Contenidos_siniestros_num\n",
      "1.00    561\n",
      "2.00     30\n",
      "3.00      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución test:\n",
      "Contenidos_siniestros_num\n",
      "1.00    141\n",
      "2.00      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separar features y target\n",
    "X = df.drop('Contenidos_siniestros_num', axis=1)\n",
    "y = df['Contenidos_siniestros_num']\n",
    "\n",
    "# Split train/test estratificado 80/20 (estratificado por frecuencia)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape} | Frecuencia promedio: {y_train.mean():.4f}\")\n",
    "print(f\"Test set:  {X_test.shape} | Frecuencia promedio: {y_test.mean():.4f}\")\n",
    "print(f\"\\nDistribución train:\\n{y_train.value_counts().sort_index()}\")\n",
    "print(f\"\\nDistribución test:\\n{y_test.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features después de preprocesamiento: 14\n",
      "Shape X_train: (594, 14)\n",
      "Shape X_test: (149, 14)\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Ajustar y transformar datos\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Obtener nombres de features después de one-hot encoding\n",
    "feature_names_num = numeric_features\n",
    "feature_names_cat = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "feature_names = list(feature_names_num) + list(feature_names_cat)\n",
    "\n",
    "# Convertir a DataFrame (mantener índices originales para alinear con y_train/y_test)\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "print(f\"\\nFeatures después de preprocesamiento: {len(feature_names)}\")\n",
    "print(f\"Shape X_train: {X_train_df.shape}\")\n",
    "print(f\"Shape X_test: {X_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Fase 1 - Multinomial Logit con Selección Backward de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELO MULTINOMIAL LOGIT COMPLETO (todas las variables)\n",
      "================================================================================\n",
      "                              MNLogit Regression Results                             \n",
      "=====================================================================================\n",
      "Dep. Variable:     Contenidos_siniestros_num   No. Observations:                  594\n",
      "Model:                               MNLogit   Df Residuals:                      564\n",
      "Method:                                  MLE   Df Model:                           28\n",
      "Date:                       Fri, 10 Oct 2025   Pseudo R-squ.:                     nan\n",
      "Time:                               00:08:43   Log-Likelihood:                    nan\n",
      "converged:                              True   LL-Null:                       -137.50\n",
      "Covariance Type:                   nonrobust   LLR p-value:                       nan\n",
      "===============================================================================================\n",
      "Contenidos_siniestros_num=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                              nan        nan        nan        nan         nan         nan\n",
      "calif_promedio                     nan        nan        nan        nan         nan         nan\n",
      "distancia_al_campus                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_2do año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_3er año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_4to año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_posgrado               nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Ciencias             nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Humanidades          nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Otro                 nan        nan        nan        nan         nan         nan\n",
      "2_o_mas_inquilinos_Si              nan        nan        nan        nan         nan         nan\n",
      "genero_Masculino                   nan        nan        nan        nan         nan         nan\n",
      "genero_No respuesta                nan        nan        nan        nan         nan         nan\n",
      "genero_Otro                        nan        nan        nan        nan         nan         nan\n",
      "extintor_incendios_Si              nan        nan        nan        nan         nan         nan\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Contenidos_siniestros_num=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                              nan        nan        nan        nan         nan         nan\n",
      "calif_promedio                     nan        nan        nan        nan         nan         nan\n",
      "distancia_al_campus                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_2do año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_3er año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_4to año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_posgrado               nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Ciencias             nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Humanidades          nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Otro                 nan        nan        nan        nan         nan         nan\n",
      "2_o_mas_inquilinos_Si              nan        nan        nan        nan         nan         nan\n",
      "genero_Masculino                   nan        nan        nan        nan         nan         nan\n",
      "genero_No respuesta                nan        nan        nan        nan         nan         nan\n",
      "genero_Otro                        nan        nan        nan        nan         nan         nan\n",
      "extintor_incendios_Si              nan        nan        nan        nan         nan         nan\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Modelo Multinomial Logit completo para referencia\n",
    "X_train_const = sm.add_constant(X_train_df)\n",
    "\n",
    "# Usar MNLogit para clasificación multinomial de frecuencia\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "\n",
    "mnlogit_full = MNLogit(y_train, X_train_const)\n",
    "result_full = mnlogit_full.fit(disp=0)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELO MULTINOMIAL LOGIT COMPLETO (todas las variables)\")\n",
    "print(\"=\" * 80)\n",
    "print(result_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SELECCIÓN BACKWARD DE VARIABLES (α = 0.05)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VARIABLES SELECCIONADAS: 14\n",
      "================================================================================\n",
      "  • calif_promedio\n",
      "  • distancia_al_campus\n",
      "  • año_cursado_2do año\n",
      "  • año_cursado_3er año\n",
      "  • año_cursado_4to año\n",
      "  • año_cursado_posgrado\n",
      "  • estudios_area_Ciencias\n",
      "  • estudios_area_Humanidades\n",
      "  • estudios_area_Otro\n",
      "  • 2_o_mas_inquilinos_Si\n",
      "  • genero_Masculino\n",
      "  • genero_No respuesta\n",
      "  • genero_Otro\n",
      "  • extintor_incendios_Si\n",
      "\n",
      "                              MNLogit Regression Results                             \n",
      "=====================================================================================\n",
      "Dep. Variable:     Contenidos_siniestros_num   No. Observations:                  594\n",
      "Model:                               MNLogit   Df Residuals:                      564\n",
      "Method:                                  MLE   Df Model:                           28\n",
      "Date:                       Fri, 10 Oct 2025   Pseudo R-squ.:                     nan\n",
      "Time:                               00:08:43   Log-Likelihood:                    nan\n",
      "converged:                              True   LL-Null:                       -137.50\n",
      "Covariance Type:                   nonrobust   LLR p-value:                       nan\n",
      "===============================================================================================\n",
      "Contenidos_siniestros_num=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                              nan        nan        nan        nan         nan         nan\n",
      "calif_promedio                     nan        nan        nan        nan         nan         nan\n",
      "distancia_al_campus                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_2do año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_3er año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_4to año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_posgrado               nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Ciencias             nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Humanidades          nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Otro                 nan        nan        nan        nan         nan         nan\n",
      "2_o_mas_inquilinos_Si              nan        nan        nan        nan         nan         nan\n",
      "genero_Masculino                   nan        nan        nan        nan         nan         nan\n",
      "genero_No respuesta                nan        nan        nan        nan         nan         nan\n",
      "genero_Otro                        nan        nan        nan        nan         nan         nan\n",
      "extintor_incendios_Si              nan        nan        nan        nan         nan         nan\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Contenidos_siniestros_num=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                              nan        nan        nan        nan         nan         nan\n",
      "calif_promedio                     nan        nan        nan        nan         nan         nan\n",
      "distancia_al_campus                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_2do año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_3er año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_4to año                nan        nan        nan        nan         nan         nan\n",
      "año_cursado_posgrado               nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Ciencias             nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Humanidades          nan        nan        nan        nan         nan         nan\n",
      "estudios_area_Otro                 nan        nan        nan        nan         nan         nan\n",
      "2_o_mas_inquilinos_Si              nan        nan        nan        nan         nan         nan\n",
      "genero_Masculino                   nan        nan        nan        nan         nan         nan\n",
      "genero_No respuesta                nan        nan        nan        nan         nan         nan\n",
      "genero_Otro                        nan        nan        nan        nan         nan         nan\n",
      "extintor_incendios_Si              nan        nan        nan        nan         nan         nan\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Selección Backward basada en p-valores con Multinomial Logit\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Realiza selección backward de variables basada en p-valores del Multinomial Logit.\n",
    "    \"\"\"\n",
    "    features = list(X.columns)\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        X_const = sm.add_constant(X[features])\n",
    "        model = MNLogit(y, X_const).fit(disp=0)\n",
    "        \n",
    "        # Obtener p-valores excluyendo la constante\n",
    "        # En MNLogit, los p-valores están organizados por clase\n",
    "        p_values = model.pvalues.iloc[:, 1:]  # Excluir constante\n",
    "        \n",
    "        # Obtener el máximo p-valor entre todas las clases\n",
    "        if p_values.empty or len(p_values.columns) == 0:\n",
    "            print(\"⚠ No hay más features para evaluar\")\n",
    "            break\n",
    "        \n",
    "        max_p_values = p_values.max(axis=0)  # Máximo p-valor por feature\n",
    "        max_p_value = max_p_values.max()\n",
    "        \n",
    "        # Si el p-valor máximo es menor o igual al nivel de significancia, todas son significativas\n",
    "        if pd.isna(max_p_value) or max_p_value <= significance_level:\n",
    "            break\n",
    "            \n",
    "        feature_to_remove = max_p_values.idxmax()\n",
    "        features.remove(feature_to_remove)\n",
    "        print(f\"Eliminando: {feature_to_remove} (p-valor: {max_p_value:.4f})\")\n",
    "    \n",
    "    return features, model\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SELECCIÓN BACKWARD DE VARIABLES (α = 0.05)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "selected_features, mnlogit_backward = backward_elimination(X_train_df, y_train, significance_level=0.05)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(f\"VARIABLES SELECCIONADAS: {len(selected_features)}\")\n",
    "print(\"=\" * 80)\n",
    "for feat in selected_features:\n",
    "    print(f\"  • {feat}\")\n",
    "print()\n",
    "print(mnlogit_backward.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES FINALES (con todos los niveles de categóricas)\n",
      "================================================================================\n",
      "\n",
      "Total features: 14\n",
      "\n",
      "Features seleccionadas:\n",
      "  ✓ 2_o_mas_inquilinos_Si\n",
      "  ✓ año_cursado_2do año\n",
      "  ✓ año_cursado_3er año\n",
      "  ✓ año_cursado_4to año\n",
      "  ✓ año_cursado_posgrado\n",
      "  ✓ calif_promedio\n",
      "  ✓ distancia_al_campus\n",
      "  ✓ estudios_area_Ciencias\n",
      "  ✓ estudios_area_Humanidades\n",
      "  ✓ estudios_area_Otro\n",
      "  ✓ extintor_incendios_Si\n",
      "  ✓ genero_Masculino\n",
      "  ✓ genero_No respuesta\n",
      "  ✓ genero_Otro\n",
      "\n",
      "Shape final - Train: (594, 14) | Test: (149, 14)\n"
     ]
    }
   ],
   "source": [
    "# Expandir variables categóricas completas\n",
    "def expand_categorical_features(selected_features, all_feature_names, categorical_features):\n",
    "    selected_cat_vars = set()\n",
    "    for feat in selected_features:\n",
    "        for cat_var in categorical_features:\n",
    "            if feat.startswith(cat_var + '_'):\n",
    "                selected_cat_vars.add(cat_var)\n",
    "                break\n",
    "    \n",
    "    final_features = []\n",
    "    for feat in selected_features:\n",
    "        is_categorical = any(feat.startswith(cat_var + '_') for cat_var in categorical_features)\n",
    "        if not is_categorical:\n",
    "            final_features.append(feat)\n",
    "    \n",
    "    for feat in all_feature_names:\n",
    "        for cat_var in selected_cat_vars:\n",
    "            if feat.startswith(cat_var + '_') and feat not in final_features:\n",
    "                final_features.append(feat)\n",
    "                break\n",
    "    \n",
    "    return sorted(final_features)\n",
    "\n",
    "final_selected_features = expand_categorical_features(selected_features, feature_names, categorical_features)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURES FINALES (con todos los niveles de categóricas)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features: {len(final_selected_features)}\")\n",
    "print(\"\\nFeatures seleccionadas:\")\n",
    "for feat in final_selected_features:\n",
    "    indicator = \"✓\" if feat in selected_features else \"+\"\n",
    "    print(f\"  {indicator} {feat}\")\n",
    "\n",
    "X_train_selected = X_train_df[final_selected_features]\n",
    "X_test_selected = X_test_df[final_selected_features]\n",
    "\n",
    "print(f\"\\nShape final - Train: {X_train_selected.shape} | Test: {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Fase 1 - LazyPredict para Identificar Mejores Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EJECUTANDO LAZYPREDICT (CLASIFICACIÓN MULTINOMIAL)\n",
      "================================================================================\n",
      "\n",
      "Dataset: 594 muestras, 14 features\n",
      "Esto puede tomar varios minutos...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1194f8bfe8428dba5b970c9cc360f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 319\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -0.057158\n",
      "[LightGBM] [Info] Start training from score -2.985682\n",
      "[LightGBM] [Info] Start training from score -5.288267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS DE LAZYPREDICT\n",
      "================================================================================\n",
      "\n",
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "DecisionTreeClassifier             0.89               0.64     0.64      0.90   \n",
      "ExtraTreeClassifier                0.91               0.60     0.60      0.91   \n",
      "PassiveAggressiveClassifier        0.93               0.55     0.55      0.92   \n",
      "NearestCentroid                    0.63               0.51     0.56      0.74   \n",
      "AdaBoostClassifier                 0.95               0.50     0.50      0.92   \n",
      "CalibratedClassifierCV             0.95               0.50     0.50      0.92   \n",
      "DummyClassifier                    0.95               0.50     0.50      0.92   \n",
      "BernoulliNB                        0.95               0.50     0.50      0.92   \n",
      "BaggingClassifier                  0.95               0.50     0.50      0.92   \n",
      "SVC                                0.95               0.50     0.50      0.92   \n",
      "RidgeClassifierCV                  0.95               0.50     0.50      0.92   \n",
      "LinearDiscriminantAnalysis         0.95               0.50     0.50      0.92   \n",
      "LogisticRegression                 0.95               0.50     0.50      0.92   \n",
      "LinearSVC                          0.95               0.50     0.50      0.92   \n",
      "SGDClassifier                      0.95               0.50     0.50      0.92   \n",
      "RandomForestClassifier             0.95               0.50     0.50      0.92   \n",
      "RidgeClassifier                    0.95               0.50     0.50      0.92   \n",
      "LGBMClassifier                     0.94               0.50     0.50      0.92   \n",
      "Perceptron                         0.94               0.50     0.50      0.92   \n",
      "KNeighborsClassifier               0.94               0.50     0.50      0.92   \n",
      "ExtraTreesClassifier               0.93               0.49     0.49      0.91   \n",
      "QuadraticDiscriminantAnalysis      0.93               0.49     0.49      0.91   \n",
      "LabelPropagation                   0.92               0.49     0.49      0.91   \n",
      "LabelSpreading                     0.92               0.49     0.49      0.91   \n",
      "GaussianNB                         0.72               0.38     0.57      0.80   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "DecisionTreeClassifier               0.01  \n",
      "ExtraTreeClassifier                  0.01  \n",
      "PassiveAggressiveClassifier          0.01  \n",
      "NearestCentroid                      0.02  \n",
      "AdaBoostClassifier                   0.09  \n",
      "CalibratedClassifierCV               0.05  \n",
      "DummyClassifier                      0.01  \n",
      "BernoulliNB                          0.01  \n",
      "BaggingClassifier                    0.03  \n",
      "SVC                                  0.01  \n",
      "RidgeClassifierCV                    0.01  \n",
      "LinearDiscriminantAnalysis           0.01  \n",
      "LogisticRegression                   0.02  \n",
      "LinearSVC                            0.01  \n",
      "SGDClassifier                        0.01  \n",
      "RandomForestClassifier               0.10  \n",
      "RidgeClassifier                      0.01  \n",
      "LGBMClassifier                       0.10  \n",
      "Perceptron                           0.01  \n",
      "KNeighborsClassifier                 0.01  \n",
      "ExtraTreesClassifier                 0.10  \n",
      "QuadraticDiscriminantAnalysis        0.01  \n",
      "LabelPropagation                     0.02  \n",
      "LabelSpreading                       0.02  \n",
      "GaussianNB                           0.01  \n"
     ]
    }
   ],
   "source": [
    "# Ejecutar LazyPredict para clasificación multinomial\n",
    "print(\"=\" * 80)\n",
    "print(\"EJECUTANDO LAZYPREDICT (CLASIFICACIÓN MULTINOMIAL)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: {X_train_selected.shape[0]} muestras, {X_train_selected.shape[1]} features\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, predictions=True, random_state=42)\n",
    "models, predictions = clf.fit(X_train_selected, X_test_selected, y_train, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESULTADOS DE LAZYPREDICT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 5 MODELOS POR F1 SCORE\n",
      "================================================================================\n",
      "\n",
      "                        Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                    \n",
      "AdaBoostClassifier          0.95               0.50     0.50      0.92   \n",
      "CalibratedClassifierCV      0.95               0.50     0.50      0.92   \n",
      "DummyClassifier             0.95               0.50     0.50      0.92   \n",
      "BernoulliNB                 0.95               0.50     0.50      0.92   \n",
      "BaggingClassifier           0.95               0.50     0.50      0.92   \n",
      "\n",
      "                        Time Taken  \n",
      "Model                               \n",
      "AdaBoostClassifier            0.09  \n",
      "CalibratedClassifierCV        0.05  \n",
      "DummyClassifier               0.01  \n",
      "BernoulliNB                   0.01  \n",
      "BaggingClassifier             0.03  \n",
      "\n",
      "================================================================================\n",
      "MODELOS SELECCIONADOS PARA FASE 2 (GridSearchCV)\n",
      "================================================================================\n",
      "\n",
      "Total modelos a optimizar: 9\n",
      "\n",
      "De LazyPredict (Top 5):\n",
      "1. AdaBoostClassifier - F1: 0.9202 | Accuracy: 0.9463\n",
      "2. CalibratedClassifierCV - F1: 0.9202 | Accuracy: 0.9463\n",
      "3. DummyClassifier - F1: 0.9202 | Accuracy: 0.9463\n",
      "4. BernoulliNB - F1: 0.9202 | Accuracy: 0.9463\n",
      "5. BaggingClassifier - F1: 0.9202 | Accuracy: 0.9463\n",
      "\n",
      "Modelos adicionales solicitados:\n",
      "  • LogisticRegression - F1: 0.9202 | Accuracy: 0.9463\n",
      "  • RandomForestClassifier - F1: 0.9202 | Accuracy: 0.9463\n",
      "  • XGBClassifier - (no evaluado en LazyPredict)\n",
      "  • GradientBoostingClassifier - (no evaluado en LazyPredict)\n"
     ]
    }
   ],
   "source": [
    "# Top 5 modelos por F1 Score (mayor es mejor para clasificación)\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 5 MODELOS POR F1 SCORE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "top_5_models = models.nlargest(5, 'F1 Score')\n",
    "print(top_5_models)\n",
    "\n",
    "# Agregar modelos adicionales solicitados explícitamente\n",
    "modelos_adicionales = ['LogisticRegression', 'RandomForestClassifier', 'XGBClassifier', 'GradientBoostingClassifier']\n",
    "modelos_para_optimizar = list(set(list(top_5_models.index) + modelos_adicionales))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODELOS SELECCIONADOS PARA FASE 2 (GridSearchCV)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal modelos a optimizar: {len(modelos_para_optimizar)}\")\n",
    "print(\"\\nDe LazyPredict (Top 5):\")\n",
    "for i, model_name in enumerate(top_5_models.index, 1):\n",
    "    f1 = top_5_models.loc[model_name, 'F1 Score']\n",
    "    acc = top_5_models.loc[model_name, 'Accuracy']\n",
    "    print(f\"{i}. {model_name} - F1: {f1:.4f} | Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nModelos adicionales solicitados:\")\n",
    "for model_name in modelos_adicionales:\n",
    "    if model_name in models.index:\n",
    "        f1 = models.loc[model_name, 'F1 Score']\n",
    "        acc = models.loc[model_name, 'Accuracy']\n",
    "        print(f\"  • {model_name} - F1: {f1:.4f} | Accuracy: {acc:.4f}\")\n",
    "    else:\n",
    "        print(f\"  • {model_name} - (no evaluado en LazyPredict)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "## Fin de Fase 1\n",
    "\n",
    "**Fase 1 completada exitosamente:**\n",
    "1. ✅ Preprocesamiento con StandardScaler + OneHotEncoder\n",
    "2. ✅ Multinomial Logit con todas las variables\n",
    "3. ✅ Selección Backward de variables (α = 0.05)\n",
    "4. ✅ Expansión de variables categóricas completas\n",
    "5. ✅ LazyPredict para identificar mejores algoritmos\n",
    "\n",
    "**Próximos pasos (Fase 2):**\n",
    "- Optimización de hiperparámetros con GridSearchCV\n",
    "- Evaluación en conjunto de test\n",
    "- Selección del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nbkrorawsm",
   "metadata": {},
   "source": [
    "---\n",
    "## FASE 2: Optimización de Hiperparámetros con GridSearchCV\n",
    "\n",
    "**Objetivo:** Optimizar los mejores modelos identificados en Fase 1 usando validación cruzada estratificada\n",
    "**Métrica de optimización:** F1-Score (weighted) - mayor es mejor\n",
    "**Métricas de evaluación:** F1-Score, Accuracy, Precision, Recall, Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ko8pyp7mgg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de evaluación definidas\n"
     ]
    }
   ],
   "source": [
    "# Función de evaluación Gini para clasificación multinomial\n",
    "def gini_coefficient_multiclass(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calcula el coeficiente de Gini promedio para clasificación multinomial.\n",
    "    Usa One-vs-Rest para cada clase.\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    \n",
    "    classes = np.unique(y_true)\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    gini_scores = []\n",
    "    for i in range(len(classes)):\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true_bin[:, i], y_pred_proba[:, i])\n",
    "            gini = 2 * auc - 1\n",
    "            gini_scores.append(gini)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return np.mean(gini_scores) if gini_scores else np.nan\n",
    "\n",
    "print(\"✓ Funciones de evaluación definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "xi0fn5p68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Grillas con parámetros de regularización/suavizado:\n",
      "  - LogisticRegression: C (regularización L1/L2) + class_weight\n",
      "  - DecisionTreeClassifier: poda (ccp_alpha) + class_weight\n",
      "  - RandomForestClassifier: poda + min_samples + class_weight\n",
      "  - GradientBoostingClassifier: learning_rate + subsample + poda\n",
      "  - AdaBoostClassifier: learning_rate + estimator\n",
      "  - XGBClassifier: reg_alpha/lambda + learning_rate\n",
      "  - KNeighborsClassifier: n_neighbors + weights\n",
      "  - SVC: C (regularización) + class_weight\n",
      "  - LinearDiscriminantAnalysis: shrinkage\n",
      "  - QuadraticDiscriminantAnalysis: reg_param\n"
     ]
    }
   ],
   "source": [
    "# Grillas de hiperparámetros con parámetros de suavizado/regularización\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],  # Inverso de regularización\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga'],  # Soporta l1 y l2 para multinomial\n",
    "        'multi_class': ['multinomial'],\n",
    "        'max_iter': [1000],\n",
    "        'class_weight': ['balanced', None],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'DecisionTreeClassifier': {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [10, 20, 50],\n",
    "        'min_samples_leaf': [5, 10, 20],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'class_weight': ['balanced', None],\n",
    "        'ccp_alpha': [0.0, 0.01, 0.05],  # Poda de complejidad\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_split': [10, 20, 50],\n",
    "        'min_samples_leaf': [5, 10, 20],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "        'ccp_alpha': [0.0, 0.01],  # Poda\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'GradientBoostingClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [10, 20],\n",
    "        'min_samples_leaf': [5, 10],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'ccp_alpha': [0.0, 0.01],  # Poda\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'AdaBoostClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "        'algorithm': ['SAMME'],\n",
    "        'estimator': [\n",
    "            DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "            DecisionTreeClassifier(max_depth=2, random_state=42),\n",
    "            DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "        ],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'XGBClassifier': {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 1.0],  # L1 regularization\n",
    "        'reg_lambda': [1, 2, 5],  # L2 regularization\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'KNeighborsClassifier': {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \n",
    "    'SVC': {\n",
    "        'C': [0.1, 1.0, 10.0],  # Regularización\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'class_weight': ['balanced', None],\n",
    "        'probability': [True],  # Para predict_proba\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'LinearDiscriminantAnalysis': {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'shrinkage': [None, 0.1, 0.5, 0.9, 'auto']\n",
    "    },\n",
    "    \n",
    "    'QuadraticDiscriminantAnalysis': {\n",
    "        'reg_param': [0.0, 0.1, 0.3, 0.5, 0.7]  # Regularización\n",
    "    }\n",
    "}\n",
    "\n",
    "model_mapping = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=42),\n",
    "    'XGBClassifier': XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "    'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "print(\"✓ Grillas con parámetros de regularización/suavizado:\")\n",
    "print(\"  - LogisticRegression: C (regularización L1/L2) + class_weight\")\n",
    "print(\"  - DecisionTreeClassifier: poda (ccp_alpha) + class_weight\")\n",
    "print(\"  - RandomForestClassifier: poda + min_samples + class_weight\")\n",
    "print(\"  - GradientBoostingClassifier: learning_rate + subsample + poda\")\n",
    "print(\"  - AdaBoostClassifier: learning_rate + estimator\")\n",
    "print(\"  - XGBClassifier: reg_alpha/lambda + learning_rate\")\n",
    "print(\"  - KNeighborsClassifier: n_neighbors + weights\")\n",
    "print(\"  - SVC: C (regularización) + class_weight\")\n",
    "print(\"  - LinearDiscriminantAnalysis: shrinkage\")\n",
    "print(\"  - QuadraticDiscriminantAnalysis: reg_param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3liy3bmnbk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID SEARCH CON VALIDACIÓN CRUZADA\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "[1/9] Optimizando: LogisticRegression\n",
      "================================================================================\n",
      "Combinaciones: 24 | Total fits: 120\n",
      "✓ F1-Score CV: 0.9175\n",
      "Mejores parámetros: {'C': 0.001, 'class_weight': None, 'max_iter': 1000, 'multi_class': 'multinomial', 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "\n",
      "================================================================================\n",
      "[2/9] Optimizando: BernoulliNB\n",
      "================================================================================\n",
      "⚠ No hay grilla para BernoulliNB, saltando...\n",
      "\n",
      "================================================================================\n",
      "[3/9] Optimizando: GradientBoostingClassifier\n",
      "================================================================================\n",
      "Combinaciones: 1296 | Total fits: 6480\n",
      "✓ F1-Score CV: 0.9255\n",
      "Mejores parámetros: {'ccp_alpha': 0.0, 'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.8}\n",
      "\n",
      "================================================================================\n",
      "[4/9] Optimizando: DummyClassifier\n",
      "================================================================================\n",
      "⚠ No hay grilla para DummyClassifier, saltando...\n",
      "\n",
      "================================================================================\n",
      "[5/9] Optimizando: AdaBoostClassifier\n",
      "================================================================================\n",
      "Combinaciones: 36 | Total fits: 180\n",
      "✓ F1-Score CV: 0.9195\n",
      "Mejores parámetros: {'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3, random_state=42), 'learning_rate': 0.1, 'n_estimators': 200, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "[6/9] Optimizando: CalibratedClassifierCV\n",
      "================================================================================\n",
      "⚠ No hay grilla para CalibratedClassifierCV, saltando...\n",
      "\n",
      "================================================================================\n",
      "[7/9] Optimizando: XGBClassifier\n",
      "================================================================================\n",
      "Combinaciones: 2187 | Total fits: 10935\n",
      "✗ Error: \n",
      "All the 10935 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10935 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/riemannintegrable/anaconda3/envs/competencia_cas_python/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/riemannintegrable/anaconda3/envs/competencia_cas_python/lib/python3.13/site-packages/xgboost/core.py\", line 705, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/riemannintegrable/anaconda3/envs/competencia_cas_python/lib/python3.13/site-packages/xgboost/sklearn.py\", line 1641, in fit\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [1. 2. 3.]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "[8/9] Optimizando: BaggingClassifier\n",
      "================================================================================\n",
      "⚠ No hay grilla para BaggingClassifier, saltando...\n",
      "\n",
      "================================================================================\n",
      "[9/9] Optimizando: RandomForestClassifier\n",
      "================================================================================\n",
      "Combinaciones: 1296 | Total fits: 6480\n",
      "✓ F1-Score CV: 0.9175\n",
      "Mejores parámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "Completado: 4/9 modelos\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV con validación cruzada\n",
    "print(\"=\" * 80)\n",
    "print(\"GRID SEARCH CON VALIDACIÓN CRUZADA\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Scorer F1-weighted (apropiado para desbalanceo de clases)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "optimized_models = {}\n",
    "grid_results = {}\n",
    "\n",
    "for i, model_name in enumerate(modelos_para_optimizar, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"[{i}/{len(modelos_para_optimizar)}] Optimizando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if model_name not in param_grids or model_name not in model_mapping:\n",
    "        print(f\"⚠ No hay grilla para {model_name}, saltando...\")\n",
    "        continue\n",
    "    \n",
    "    base_model = model_mapping[model_name]\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    n_combinations = np.prod([len(v) if isinstance(v, list) else 1 for v in param_grid.values()])\n",
    "    print(f\"Combinaciones: {int(n_combinations)} | Total fits: {int(5 * n_combinations)}\")\n",
    "    \n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=f1_scorer,  # Optimiza F1-score weighted\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_selected, y_train)\n",
    "        \n",
    "        optimized_models[model_name] = grid_search.best_estimator_\n",
    "        grid_results[model_name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score_cv': grid_search.best_score_\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ F1-Score CV: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Completado: {len(optimized_models)}/{len(modelos_para_optimizar)} modelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "mqs54cti70h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACIÓN EN TEST SET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Evaluando: LogisticRegression\n",
      "================================================================================\n",
      "F1 (CV): 0.9175 | F1 (Test): 0.9202\n",
      "Accuracy: 0.9463 | Precision: 0.8955 | Recall: 0.9463\n",
      "Gini: 0.0000\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[141   0]\n",
      " [  8   0]]\n",
      "\n",
      "Distribución de predicciones:\n",
      "  Predicho: {1.0: np.int64(149)}\n",
      "  Real:     {1.0: np.int64(141), 2.0: np.int64(8)}\n",
      "\n",
      "================================================================================\n",
      "Evaluando: GradientBoostingClassifier\n",
      "================================================================================\n",
      "F1 (CV): 0.9255 | F1 (Test): 0.9353\n",
      "Accuracy: 0.9530 | Precision: 0.9552 | Recall: 0.9530\n",
      "Gini: -0.1348\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[141   0]\n",
      " [  7   1]]\n",
      "\n",
      "Distribución de predicciones:\n",
      "  Predicho: {1.0: np.int64(148), 2.0: np.int64(1)}\n",
      "  Real:     {1.0: np.int64(141), 2.0: np.int64(8)}\n",
      "\n",
      "================================================================================\n",
      "Evaluando: AdaBoostClassifier\n",
      "================================================================================\n",
      "F1 (CV): 0.9195 | F1 (Test): 0.9353\n",
      "Accuracy: 0.9530 | Precision: 0.9552 | Recall: 0.9530\n",
      "Gini: -0.1658\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[141   0]\n",
      " [  7   1]]\n",
      "\n",
      "Distribución de predicciones:\n",
      "  Predicho: {1.0: np.int64(148), 2.0: np.int64(1)}\n",
      "  Real:     {1.0: np.int64(141), 2.0: np.int64(8)}\n",
      "\n",
      "================================================================================\n",
      "Evaluando: RandomForestClassifier\n",
      "================================================================================\n",
      "F1 (CV): 0.9175 | F1 (Test): 0.9202\n",
      "Accuracy: 0.9463 | Precision: 0.8955 | Recall: 0.9463\n",
      "Gini: -0.0957\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[141   0]\n",
      " [  8   0]]\n",
      "\n",
      "Distribución de predicciones:\n",
      "  Predicho: {1.0: np.int64(149)}\n",
      "  Real:     {1.0: np.int64(141), 2.0: np.int64(8)}\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE RESULTADOS (ordenado por F1-Score Test)\n",
      "================================================================================\n",
      "\n",
      "                    Modelo  F1_CV  F1_Test  Accuracy  Precision  Recall  Gini\n",
      "GradientBoostingClassifier   0.93     0.94      0.95       0.96    0.95 -0.13\n",
      "        AdaBoostClassifier   0.92     0.94      0.95       0.96    0.95 -0.17\n",
      "        LogisticRegression   0.92     0.92      0.95       0.90    0.95  0.00\n",
      "    RandomForestClassifier   0.92     0.92      0.95       0.90    0.95 -0.10\n"
     ]
    }
   ],
   "source": [
    "# Evaluación en test set\n",
    "print(\"=\" * 80)\n",
    "print(\"EVALUACIÓN EN TEST SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for model_name, model in optimized_models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Predicciones en test\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # Predicciones de probabilidad (si el modelo lo soporta)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test_selected)\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_pred_proba = None  # No todas las decisiones son probabilidades\n",
    "    else:\n",
    "        y_pred_proba = None\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Calcular Gini si hay probabilidades\n",
    "    try:\n",
    "        if y_pred_proba is not None:\n",
    "            gini = gini_coefficient_multiclass(y_test, y_pred_proba)\n",
    "        else:\n",
    "            gini = np.nan\n",
    "    except:\n",
    "        gini = np.nan\n",
    "    \n",
    "    test_results.append({\n",
    "        'Modelo': model_name,\n",
    "        'F1_CV': grid_results[model_name]['best_score_cv'],\n",
    "        'F1_Test': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Gini': gini\n",
    "    })\n",
    "    \n",
    "    print(f\"F1 (CV): {grid_results[model_name]['best_score_cv']:.4f} | F1 (Test): {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "    print(f\"Gini: {gini:.4f}\")\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nMatriz de Confusión:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Distribución de predicciones\n",
    "    print(f\"\\nDistribución de predicciones:\")\n",
    "    pred_dist = pd.Series(y_pred).value_counts().sort_index()\n",
    "    real_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "    print(f\"  Predicho: {dict(pred_dist)}\")\n",
    "    print(f\"  Real:     {dict(real_dist)}\")\n",
    "\n",
    "df_results = pd.DataFrame(test_results).sort_values('F1_Test', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESUMEN DE RESULTADOS (ordenado por F1-Score Test)\")\n",
    "print(f\"{'='*80}\")\n",
    "print()\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b83df5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REENTRENAMIENTO CON DATASET COMPLETO\n",
      "================================================================================\n",
      "\n",
      "Dataset completo: (743, 14)\n",
      "Distribución de frecuencia:\n",
      "Contenidos_siniestros_num\n",
      "1.00    702\n",
      "2.00     38\n",
      "3.00      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mejores parámetros del GradientBoostingClassifier:\n",
      "  ccp_alpha: 0.0\n",
      "  learning_rate: 0.1\n",
      "  max_depth: 7\n",
      "  max_features: sqrt\n",
      "  min_samples_leaf: 5\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 100\n",
      "  random_state: 42\n",
      "  subsample: 0.8\n",
      "\n",
      "✓ Modelo reentrenado con 743 registros\n",
      "================================================================================\n",
      "MODELO EXPORTADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "Ruta: ../models/frecuencia_contenidos.pkl\n",
      "\n",
      "Modelo: GradientBoostingClassifier\n",
      "Mejores parámetros: {'ccp_alpha': 0.0, 'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.8}\n",
      "\n",
      "Métricas en Test Set:\n",
      "  F1-Score: 0.9353\n",
      "  Accuracy: 0.9530\n",
      "  Precision: 0.9552\n",
      "  Recall: 0.9530\n",
      "  Gini: -0.1348\n",
      "\n",
      "Contenido del archivo:\n",
      "  • modelo: GradientBoostingClassifier optimizado\n",
      "  • preprocessor: ColumnTransformer (StandardScaler + OneHotEncoder)\n",
      "  • features_seleccionadas: ['2_o_mas_inquilinos_Si', 'año_cursado_2do año', 'año_cursado_3er año', 'año_cursado_4to año', 'año_cursado_posgrado', 'calif_promedio', 'distancia_al_campus', 'estudios_area_Ciencias', 'estudios_area_Humanidades', 'estudios_area_Otro', 'extintor_incendios_Si', 'genero_Masculino', 'genero_No respuesta', 'genero_Otro']\n",
      "  • metricas: diccionario con todas las métricas\n",
      "  • mejores_parametros: {'ccp_alpha': 0.0, 'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "  print(\"=\" * 80)\n",
    "  print(\"REENTRENAMIENTO CON DATASET COMPLETO\")\n",
    "  print(\"=\" * 80)\n",
    "  print()\n",
    "\n",
    "  # Combinar train y test\n",
    "  X_full = pd.concat([X_train_selected, X_test_selected])\n",
    "  y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "  print(f\"Dataset completo: {X_full.shape}\")\n",
    "  print(f\"Distribución de frecuencia:\\n{y_full.value_counts().sort_index()}\")\n",
    "\n",
    "  # Obtener los mejores parámetros del\n",
    "  GradientBoostingClassifier\n",
    "  best_params_gbc = grid_results['GradientBoostingClassifier']['best_params']\n",
    "  print(f\"\\nMejores parámetros del GradientBoostingClassifier:\")\n",
    "  for param, value in best_params_gbc.items():\n",
    "      print(f\"  {param}: {value}\")\n",
    "\n",
    "  # Crear y entrenar modelo con todos los datos\n",
    "  gbc_final = GradientBoostingClassifier(**best_params_gbc)\n",
    "  gbc_final.fit(X_full, y_full)\n",
    "\n",
    "  print(f\"\\n✓ Modelo reentrenado con {len(X_full)} registros\")\n",
    "\n",
    "  # Celda 2: Exportación del modelo\n",
    "  import pickle\n",
    "  import os\n",
    "\n",
    "  # Crear directorio models si no existe\n",
    "  os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "  # Preparar objeto para exportar\n",
    "  modelo_export = {\n",
    "      'modelo': gbc_final,\n",
    "      'preprocessor': preprocessor,\n",
    "      'features_seleccionadas': final_selected_features,\n",
    "      'metricas': {\n",
    "          'F1_CV': grid_results['GradientBoostingClassifier']['best_score_cv'],\n",
    "          'F1_Test': df_results[df_results['Modelo'] == 'GradientBoostingClassifier']['F1_Test'].values[0],\n",
    "          'Accuracy': df_results[df_results['Modelo'] == 'GradientBoostingClassifier']['Accuracy'].values[0],\n",
    "          'Precision': df_results[df_results['Modelo'] == 'GradientBoostingClassifier']['Precision'].values[0],\n",
    "          'Recall': df_results[df_results['Modelo'] == 'GradientBoostingClassifier']['Recall'].values[0],\n",
    "          'Gini': df_results[df_results['Modelo'] == 'GradientBoostingClassifier']['Gini'].values[0]\n",
    "      },\n",
    "      'mejores_parametros': best_params_gbc\n",
    "  }\n",
    "\n",
    "  # Exportar modelo\n",
    "  model_path = '../models/frecuencia_contenidos.pkl'\n",
    "  with open(model_path, 'wb') as f:\n",
    "      pickle.dump(modelo_export, f)\n",
    "\n",
    "  print(\"=\" * 80)\n",
    "  print(\"MODELO EXPORTADO EXITOSAMENTE\")\n",
    "  print(\"=\" * 80)\n",
    "  print(f\"\\nRuta: {model_path}\")\n",
    "  print(f\"\\nModelo: GradientBoostingClassifier\")\n",
    "  print(f\"Mejores parámetros: {modelo_export['mejores_parametros']}\")\n",
    "  print(f\"\\nMétricas en Test Set:\")\n",
    "  print(f\"  F1-Score: {modelo_export['metricas']['F1_Test']:.4f}\")\n",
    "  print(f\"  Accuracy: {modelo_export['metricas']['Accuracy']:.4f}\")\n",
    "  print(f\"  Precision: {modelo_export['metricas']['Precision']:.4f}\")\n",
    "  print(f\"  Recall: {modelo_export['metricas']['Recall']:.4f}\")\n",
    "  print(f\"  Gini: {modelo_export['metricas']['Gini']:.4f}\")\n",
    "  print(f\"\\nContenido del archivo:\")\n",
    "  print(f\"  • modelo: GradientBoostingClassifier optimizado\")\n",
    "  print(f\"  • preprocessor: ColumnTransformer (StandardScaler + OneHotEncoder)\")\n",
    "  print(f\"  • features_seleccionadas: {final_selected_features}\")\n",
    "  print(f\"  • metricas: diccionario con todas las métricas\")\n",
    "  print(f\"  • mejores_parametros: {modelo_export['mejores_parametros']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
