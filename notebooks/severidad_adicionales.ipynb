{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Severidad - Gastos Adicionales de Vivienda\n",
    "\n",
    "## Objetivo\n",
    "Predecir la **severidad promedio** (monto promedio por siniestro) de la cobertura de Gastos Adicionales de Vivienda para asegurados que ya tuvieron siniestros.\n",
    "\n",
    "## Pipeline\n",
    "1. **Fase 1**: Preprocesamiento + GLM Lognormal + Selección Backward\n",
    "2. **Fase 2**: LazyPredict con variables seleccionadas\n",
    "3. **Fase 3**: Evaluación con MAE y GINI\n",
    "\n",
    "**Dataset**: Solo registros siniestrados de Gastos Adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, OrthogonalMatchingPursuitCV\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    BaggingRegressor, HistGradientBoostingRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, make_scorer\n",
    "\n",
    "# LazyPredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# Selección de variables con GLM\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Gamma\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original: (416, 15)\n",
      "\n",
      "Columnas: ['año_cursado', 'estudios_area', 'calif_promedio', '2_o_mas_inquilinos', 'distancia_al_campus', 'genero', 'extintor_incendios', 'Gastos_Adicionales_siniestros_num', 'Gastos_Adicionales_siniestros_monto', 'Gastos_Medicos_RC_siniestros_num', 'Gastos_Medicos_RC_siniestros_monto', 'Resp_Civil_siniestros_num', 'Resp_Civil_siniestros_monto', 'Contenidos_siniestros_num', 'Contenidos_siniestros_monto']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año_cursado</th>\n",
       "      <th>estudios_area</th>\n",
       "      <th>calif_promedio</th>\n",
       "      <th>2_o_mas_inquilinos</th>\n",
       "      <th>distancia_al_campus</th>\n",
       "      <th>genero</th>\n",
       "      <th>extintor_incendios</th>\n",
       "      <th>Gastos_Adicionales_siniestros_num</th>\n",
       "      <th>Gastos_Adicionales_siniestros_monto</th>\n",
       "      <th>Gastos_Medicos_RC_siniestros_num</th>\n",
       "      <th>Gastos_Medicos_RC_siniestros_monto</th>\n",
       "      <th>Resp_Civil_siniestros_num</th>\n",
       "      <th>Resp_Civil_siniestros_monto</th>\n",
       "      <th>Contenidos_siniestros_num</th>\n",
       "      <th>Contenidos_siniestros_monto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3er año</td>\n",
       "      <td>Humanidades</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.33</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8909.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3er año</td>\n",
       "      <td>Otro</td>\n",
       "      <td>7.42</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.00</td>\n",
       "      <td>366.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2do año</td>\n",
       "      <td>Humanidades</td>\n",
       "      <td>5.09</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2936.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>posgrado</td>\n",
       "      <td>Ciencias</td>\n",
       "      <td>7.48</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3989.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1er año</td>\n",
       "      <td>Ciencias</td>\n",
       "      <td>8.56</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>No</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14256.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  año_cursado estudios_area  calif_promedio 2_o_mas_inquilinos  \\\n",
       "0     3er año   Humanidades            4.78                 Si   \n",
       "1     3er año          Otro            7.42                 Si   \n",
       "2     2do año   Humanidades            5.09                 No   \n",
       "3    posgrado      Ciencias            7.48                 No   \n",
       "4     1er año      Ciencias            8.56                 Si   \n",
       "\n",
       "   distancia_al_campus     genero extintor_incendios  \\\n",
       "0                 1.33  Masculino                 Si   \n",
       "1                 0.00   Femenino                 Si   \n",
       "2                 0.00   Femenino                 Si   \n",
       "3                 0.00   Femenino                 Si   \n",
       "4                 1.45  Masculino                 No   \n",
       "\n",
       "   Gastos_Adicionales_siniestros_num  Gastos_Adicionales_siniestros_monto  \\\n",
       "0                               1.00                              8909.20   \n",
       "1                               1.00                               366.11   \n",
       "2                               1.00                              2936.17   \n",
       "3                               1.00                              3989.42   \n",
       "4                               1.00                             14256.36   \n",
       "\n",
       "   Gastos_Medicos_RC_siniestros_num  Gastos_Medicos_RC_siniestros_monto  \\\n",
       "0                              0.00                                0.00   \n",
       "1                              0.00                                0.00   \n",
       "2                              0.00                                0.00   \n",
       "3                              0.00                                0.00   \n",
       "4                              0.00                                0.00   \n",
       "\n",
       "   Resp_Civil_siniestros_num  Resp_Civil_siniestros_monto  \\\n",
       "0                       0.00                         0.00   \n",
       "1                       0.00                         0.00   \n",
       "2                       0.00                         0.00   \n",
       "3                       0.00                         0.00   \n",
       "4                       0.00                         0.00   \n",
       "\n",
       "   Contenidos_siniestros_num  Contenidos_siniestros_monto  \n",
       "0                       0.00                         0.00  \n",
       "1                       0.00                         0.00  \n",
       "2                       0.00                         0.00  \n",
       "3                       0.00                         0.00  \n",
       "4                       0.00                         0.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos de siniestrados\n",
    "df = pd.read_csv(\"../data/processed/adicionales_siniestrados.csv\")\n",
    "\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "print(f\"\\nColumnas: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset preparado: (416, 8)\n",
      "\n",
      "Estadísticas de severidad:\n",
      "count     416.00\n",
      "mean     5391.41\n",
      "std      4918.52\n",
      "min       274.93\n",
      "25%      2335.55\n",
      "50%      3836.00\n",
      "75%      6414.70\n",
      "max     36503.68\n",
      "Name: severidad, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear variable objetivo: Severidad = Monto / Número de siniestros\n",
    "df['severidad'] = df['Gastos_Adicionales_siniestros_monto'] / df['Gastos_Adicionales_siniestros_num']\n",
    "\n",
    "# Eliminar columnas originales de monto y número\n",
    "df = df.drop(['Gastos_Adicionales_siniestros_monto', 'Gastos_Adicionales_siniestros_num'], axis=1)\n",
    "\n",
    "# Eliminar también las otras coberturas (no se usan para este modelo)\n",
    "columnas_otras_coberturas = [\n",
    "    'Gastos_Medicos_RC_siniestros_num', 'Gastos_Medicos_RC_siniestros_monto',\n",
    "    'Resp_Civil_siniestros_num', 'Resp_Civil_siniestros_monto',\n",
    "    'Contenidos_siniestros_num', 'Contenidos_siniestros_monto'\n",
    "]\n",
    "df = df.drop(columnas_otras_coberturas, axis=1)\n",
    "\n",
    "print(f\"\\nDataset preparado: {df.shape}\")\n",
    "print(f\"\\nEstadísticas de severidad:\")\n",
    "print(df['severidad'].describe())\n",
    "\n",
    "# Visualizar distribución de severidad\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['severidad'], bins=50, edgecolor='black')\n",
    "plt.xlabel('Severidad (USD)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de Severidad')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log(df['severidad']), bins=50, edgecolor='black')\n",
    "plt.xlabel('log(Severidad)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de log(Severidad)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identificación de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables numéricas: ['calif_promedio', 'distancia_al_campus']\n",
      "Variables categóricas: ['año_cursado', 'estudios_area', '2_o_mas_inquilinos', 'genero', 'extintor_incendios']\n",
      "\n",
      "Total features: 7\n",
      "\n",
      "Valores faltantes:\n",
      "año_cursado            0\n",
      "estudios_area          0\n",
      "calif_promedio         0\n",
      "2_o_mas_inquilinos     0\n",
      "distancia_al_campus    0\n",
      "genero                 0\n",
      "extintor_incendios     0\n",
      "severidad              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificar tipos de variables\n",
    "numeric_features = ['calif_promedio', 'distancia_al_campus']\n",
    "categorical_features = ['año_cursado', 'estudios_area', '2_o_mas_inquilinos', 'genero', 'extintor_incendios']\n",
    "\n",
    "print(\"Variables numéricas:\", numeric_features)\n",
    "print(\"Variables categóricas:\", categorical_features)\n",
    "print(f\"\\nTotal features: {len(numeric_features) + len(categorical_features)}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"\\nValores faltantes:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento y Split de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (332, 7) | Severidad promedio: $5260.19\n",
      "Test set:  (84, 7) | Severidad promedio: $5910.05\n"
     ]
    }
   ],
   "source": [
    "# Separar features y target\n",
    "X = df.drop('severidad', axis=1)\n",
    "y = df['severidad']\n",
    "\n",
    "# Split train/test 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape} | Severidad promedio: ${y_train.mean():.2f}\")\n",
    "print(f\"Test set:  {X_test.shape} | Severidad promedio: ${y_test.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features después de preprocesamiento: 14\n",
      "Shape X_train: (332, 14)\n",
      "Shape X_test: (84, 14)\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Ajustar y transformar datos\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Obtener nombres de features después de one-hot encoding\n",
    "feature_names_num = numeric_features\n",
    "feature_names_cat = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "feature_names = list(feature_names_num) + list(feature_names_cat)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "print(f\"\\nFeatures después de preprocesamiento: {len(feature_names)}\")\n",
    "print(f\"Shape X_train: {X_train_df.shape}\")\n",
    "print(f\"Shape X_test: {X_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fase 1 - GLM Lognormal con Selección Backward de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELO GLM LOGNORMAL COMPLETO (todas las variables)\n",
      "================================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              severidad   No. Observations:                  332\n",
      "Model:                            GLM   Df Residuals:                      317\n",
      "Model Family:                   Gamma   Df Model:                           14\n",
      "Link Function:                    Log   Scale:                         0.31613\n",
      "Method:                          IRLS   Log-Likelihood:                -3046.9\n",
      "Date:                Fri, 10 Oct 2025   Deviance:                       114.01\n",
      "Time:                        00:38:05   Pearson chi2:                     100.\n",
      "No. Iterations:                    13   Pseudo R-squ. (CS):             0.5640\n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         8.2174      0.096     85.787      0.000       8.030       8.405\n",
      "calif_promedio                0.0045      0.031      0.142      0.887      -0.057       0.066\n",
      "distancia_al_campus           0.1550      0.032      4.817      0.000       0.092       0.218\n",
      "año_cursado_2do año           0.0836      0.095      0.880      0.379      -0.103       0.270\n",
      "año_cursado_3er año           0.3475      0.090      3.854      0.000       0.171       0.524\n",
      "año_cursado_4to año           0.3822      0.089      4.296      0.000       0.208       0.557\n",
      "año_cursado_posgrado          0.4588      0.122      3.766      0.000       0.220       0.698\n",
      "estudios_area_Ciencias        0.1822      0.089      2.050      0.040       0.008       0.356\n",
      "estudios_area_Humanidades     0.1643      0.091      1.813      0.070      -0.013       0.342\n",
      "estudios_area_Otro            0.0963      0.083      1.165      0.244      -0.066       0.258\n",
      "2_o_mas_inquilinos_Si         0.7517      0.068     11.087      0.000       0.619       0.885\n",
      "genero_Masculino             -0.0161      0.065     -0.248      0.804      -0.143       0.111\n",
      "genero_No respuesta           0.4037      0.197      2.049      0.040       0.017       0.790\n",
      "genero_Otro                  -0.0299      0.154     -0.194      0.846      -0.332       0.273\n",
      "extintor_incendios_Si        -0.5250      0.066     -7.942      0.000      -0.655      -0.395\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Modelo GLM con distribución Gamma (lognormal) para referencia\n",
    "X_train_const = sm.add_constant(X_train_df)\n",
    "\n",
    "# GLM con familia Gamma y link log (apropiado para severidad)\n",
    "glm_full = sm.GLM(y_train, X_train_const, family=Gamma(link=sm.families.links.Log()))\n",
    "result_full = glm_full.fit()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELO GLM LOGNORMAL COMPLETO (todas las variables)\")\n",
    "print(\"=\" * 80)\n",
    "print(result_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SELECCIÓN BACKWARD DE VARIABLES (α = 0.1)\n",
      "================================================================================\n",
      "\n",
      "Eliminando: calif_promedio (p-valor: 0.8871)\n",
      "Eliminando: genero_Otro (p-valor: 0.8376)\n",
      "Eliminando: genero_Masculino (p-valor: 0.8380)\n",
      "Eliminando: año_cursado_2do año (p-valor: 0.3891)\n",
      "Eliminando: estudios_area_Otro (p-valor: 0.2396)\n",
      "Eliminando: estudios_area_Humanidades (p-valor: 0.1335)\n",
      "Eliminando: estudios_area_Ciencias (p-valor: 0.1942)\n",
      "\n",
      "================================================================================\n",
      "VARIABLES SELECCIONADAS: 7\n",
      "================================================================================\n",
      "  • distancia_al_campus\n",
      "  • año_cursado_3er año\n",
      "  • año_cursado_4to año\n",
      "  • año_cursado_posgrado\n",
      "  • 2_o_mas_inquilinos_Si\n",
      "  • genero_No respuesta\n",
      "  • extintor_incendios_Si\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              severidad   No. Observations:                  332\n",
      "Model:                            GLM   Df Residuals:                      324\n",
      "Model Family:                   Gamma   Df Model:                            7\n",
      "Link Function:                    Log   Scale:                         0.31994\n",
      "Method:                          IRLS   Log-Likelihood:                -3049.9\n",
      "Date:                Fri, 10 Oct 2025   Deviance:                       115.95\n",
      "Time:                        00:38:05   Pearson chi2:                     104.\n",
      "No. Iterations:                    13   Pseudo R-squ. (CS):             0.5516\n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     8.3428      0.066    126.691      0.000       8.214       8.472\n",
      "distancia_al_campus       0.1634      0.031      5.217      0.000       0.102       0.225\n",
      "año_cursado_3er año       0.3002      0.081      3.711      0.000       0.142       0.459\n",
      "año_cursado_4to año       0.3264      0.080      4.104      0.000       0.171       0.482\n",
      "año_cursado_posgrado      0.4216      0.115      3.660      0.000       0.196       0.647\n",
      "2_o_mas_inquilinos_Si     0.7656      0.067     11.397      0.000       0.634       0.897\n",
      "genero_No respuesta       0.4394      0.193      2.274      0.023       0.061       0.818\n",
      "extintor_incendios_Si    -0.5130      0.066     -7.752      0.000      -0.643      -0.383\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Selección Backward basada en p-valores\n",
    "def backward_elimination_glm(X, y, significance_level=0.1):\n",
    "    \"\"\"\n",
    "    Realiza selección backward de variables basada en p-valores del GLM Lognormal.\n",
    "    \"\"\"\n",
    "    features = list(X.columns)\n",
    "    \n",
    "    while True:\n",
    "        X_const = sm.add_constant(X[features])\n",
    "        model = sm.GLM(y, X_const, family=Gamma(link=sm.families.links.Log())).fit()\n",
    "        p_values = model.pvalues.iloc[1:]  # Excluir constante\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value <= significance_level:\n",
    "            break\n",
    "            \n",
    "        feature_to_remove = p_values.idxmax()\n",
    "        features.remove(feature_to_remove)\n",
    "        print(f\"Eliminando: {feature_to_remove} (p-valor: {max_p_value:.4f})\")\n",
    "    \n",
    "    return features, model\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SELECCIÓN BACKWARD DE VARIABLES (α = 0.1)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "selected_features, glm_backward = backward_elimination_glm(X_train_df, y_train, significance_level=0.1)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(f\"VARIABLES SELECCIONADAS: {len(selected_features)}\")\n",
    "print(\"=\" * 80)\n",
    "for feat in selected_features:\n",
    "    print(f\"  • {feat}\")\n",
    "print()\n",
    "print(glm_backward.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES FINALES (con todos los niveles de categóricas)\n",
      "================================================================================\n",
      "\n",
      "Total features: 10\n",
      "\n",
      "Features seleccionadas:\n",
      "  ✓ 2_o_mas_inquilinos_Si\n",
      "  + año_cursado_2do año\n",
      "  ✓ año_cursado_3er año\n",
      "  ✓ año_cursado_4to año\n",
      "  ✓ año_cursado_posgrado\n",
      "  ✓ distancia_al_campus\n",
      "  ✓ extintor_incendios_Si\n",
      "  + genero_Masculino\n",
      "  ✓ genero_No respuesta\n",
      "  + genero_Otro\n",
      "\n",
      "Shape final - Train: (332, 10) | Test: (84, 10)\n"
     ]
    }
   ],
   "source": [
    "# Expandir variables categóricas completas\n",
    "def expand_categorical_features(selected_features, all_feature_names, categorical_features):\n",
    "    \"\"\"\n",
    "    Si se seleccionó un nivel de una variable categórica, incluir todos sus niveles.\n",
    "    \"\"\"\n",
    "    selected_cat_vars = set()\n",
    "    for feat in selected_features:\n",
    "        for cat_var in categorical_features:\n",
    "            if feat.startswith(cat_var + '_'):\n",
    "                selected_cat_vars.add(cat_var)\n",
    "                break\n",
    "    \n",
    "    # Incluir variables numéricas seleccionadas\n",
    "    final_features = []\n",
    "    for feat in selected_features:\n",
    "        is_categorical = any(feat.startswith(cat_var + '_') for cat_var in categorical_features)\n",
    "        if not is_categorical:\n",
    "            final_features.append(feat)\n",
    "    \n",
    "    # Agregar todos los niveles de las categóricas seleccionadas\n",
    "    for feat in all_feature_names:\n",
    "        for cat_var in selected_cat_vars:\n",
    "            if feat.startswith(cat_var + '_') and feat not in final_features:\n",
    "                final_features.append(feat)\n",
    "                break\n",
    "    \n",
    "    return sorted(final_features)\n",
    "\n",
    "final_selected_features = expand_categorical_features(selected_features, feature_names, categorical_features)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURES FINALES (con todos los niveles de categóricas)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features: {len(final_selected_features)}\")\n",
    "print(\"\\nFeatures seleccionadas:\")\n",
    "for feat in final_selected_features:\n",
    "    indicator = \"✓\" if feat in selected_features else \"+\"\n",
    "    print(f\"  {indicator} {feat}\")\n",
    "\n",
    "X_train_selected = X_train_df[final_selected_features]\n",
    "X_test_selected = X_test_df[final_selected_features]\n",
    "\n",
    "print(f\"\\nShape final - Train: {X_train_selected.shape} | Test: {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fase 2 - LazyPredict para Identificar Mejores Regresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EJECUTANDO LAZYPREDICT (REGRESIÓN)\n",
      "================================================================================\n",
      "\n",
      "Dataset: 332 muestras, 10 features\n",
      "Esto puede tomar varios minutos...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec8d18f19c4417dbd84e822ebccfe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 69\n",
      "[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 5260.194521\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS DE LAZYPREDICT\n",
      "================================================================================\n",
      "\n",
      "                               Adjusted R-Squared  R-Squared      RMSE  \\\n",
      "Model                                                                    \n",
      "AdaBoostRegressor                            0.49       0.55   3903.62   \n",
      "GradientBoostingRegressor                    0.47       0.53   3978.06   \n",
      "PoissonRegressor                             0.40       0.48   4203.67   \n",
      "BaggingRegressor                             0.40       0.47   4208.08   \n",
      "HistGradientBoostingRegressor                0.40       0.47   4229.34   \n",
      "LGBMRegressor                                0.39       0.47   4235.94   \n",
      "XGBRegressor                                 0.39       0.46   4263.15   \n",
      "RandomForestRegressor                        0.38       0.45   4300.00   \n",
      "OrthogonalMatchingPursuitCV                  0.37       0.44   4329.43   \n",
      "Lars                                         0.35       0.43   4384.90   \n",
      "TransformedTargetRegressor                   0.35       0.43   4384.90   \n",
      "LinearRegression                             0.35       0.43   4384.90   \n",
      "LassoLars                                    0.35       0.43   4385.47   \n",
      "Lasso                                        0.35       0.43   4385.47   \n",
      "Ridge                                        0.35       0.43   4386.75   \n",
      "LassoCV                                      0.35       0.43   4387.43   \n",
      "LassoLarsCV                                  0.35       0.43   4387.92   \n",
      "SGDRegressor                                 0.35       0.43   4390.66   \n",
      "LarsCV                                       0.35       0.43   4395.88   \n",
      "RidgeCV                                      0.35       0.42   4403.86   \n",
      "LassoLarsIC                                  0.34       0.42   4406.21   \n",
      "BayesianRidge                                0.34       0.42   4412.14   \n",
      "ExtraTreesRegressor                          0.31       0.40   4504.33   \n",
      "HuberRegressor                               0.28       0.37   4612.16   \n",
      "DecisionTreeRegressor                        0.27       0.36   4654.70   \n",
      "ElasticNet                                   0.25       0.34   4707.65   \n",
      "PassiveAggressiveRegressor                   0.23       0.32   4771.73   \n",
      "ExtraTreeRegressor                           0.22       0.31   4816.02   \n",
      "KNeighborsRegressor                          0.21       0.30   4851.53   \n",
      "OrthogonalMatchingPursuit                    0.20       0.30   4855.71   \n",
      "TweedieRegressor                             0.18       0.28   4939.58   \n",
      "GammaRegressor                               0.15       0.26   5006.47   \n",
      "ElasticNetCV                                 0.08       0.19   5215.88   \n",
      "DummyRegressor                              -0.15      -0.01   5838.90   \n",
      "NuSVR                                       -0.22      -0.07   6009.39   \n",
      "QuantileRegressor                           -0.30      -0.14   6203.46   \n",
      "SVR                                         -0.30      -0.14   6203.70   \n",
      "RANSACRegressor                             -0.37      -0.20   6360.67   \n",
      "KernelRidge                                 -0.83      -0.61   7364.73   \n",
      "LinearSVR                                   -1.19      -0.93   8050.99   \n",
      "MLPRegressor                                -1.29      -1.01   8230.15   \n",
      "GaussianProcessRegressor                 -3999.07   -3517.13 344176.14   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "AdaBoostRegressor                    0.07  \n",
      "GradientBoostingRegressor            0.04  \n",
      "PoissonRegressor                     0.01  \n",
      "BaggingRegressor                     0.02  \n",
      "HistGradientBoostingRegressor        0.08  \n",
      "LGBMRegressor                        0.03  \n",
      "XGBRegressor                         0.18  \n",
      "RandomForestRegressor                0.09  \n",
      "OrthogonalMatchingPursuitCV          0.01  \n",
      "Lars                                 0.01  \n",
      "TransformedTargetRegressor           0.01  \n",
      "LinearRegression                     0.01  \n",
      "LassoLars                            0.01  \n",
      "Lasso                                0.01  \n",
      "Ridge                                0.01  \n",
      "LassoCV                              0.04  \n",
      "LassoLarsCV                          0.02  \n",
      "SGDRegressor                         0.01  \n",
      "LarsCV                               0.02  \n",
      "RidgeCV                              0.01  \n",
      "LassoLarsIC                          0.01  \n",
      "BayesianRidge                        0.01  \n",
      "ExtraTreesRegressor                  0.07  \n",
      "HuberRegressor                       0.01  \n",
      "DecisionTreeRegressor                0.01  \n",
      "ElasticNet                           0.01  \n",
      "PassiveAggressiveRegressor           0.01  \n",
      "ExtraTreeRegressor                   0.01  \n",
      "KNeighborsRegressor                  0.01  \n",
      "OrthogonalMatchingPursuit            0.01  \n",
      "TweedieRegressor                     0.01  \n",
      "GammaRegressor                       0.01  \n",
      "ElasticNetCV                         0.04  \n",
      "DummyRegressor                       0.01  \n",
      "NuSVR                                0.01  \n",
      "QuantileRegressor                    0.02  \n",
      "SVR                                  0.01  \n",
      "RANSACRegressor                      0.05  \n",
      "KernelRidge                          0.01  \n",
      "LinearSVR                            0.00  \n",
      "MLPRegressor                         0.14  \n",
      "GaussianProcessRegressor             0.01  \n"
     ]
    }
   ],
   "source": [
    "# Ejecutar LazyPredict\n",
    "print(\"=\" * 80)\n",
    "print(\"EJECUTANDO LAZYPREDICT (REGRESIÓN)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: {X_train_selected.shape[0]} muestras, {X_train_selected.shape[1]} features\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, predictions=True, random_state=42)\n",
    "models, predictions = reg.fit(X_train_selected, X_test_selected, y_train, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESULTADOS DE LAZYPREDICT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cálculo de Métricas: MAE y GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Función de cálculo de Gini definida\n"
     ]
    }
   ],
   "source": [
    "# Función para calcular coeficiente de Gini\n",
    "def gini_coefficient(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula el coeficiente de Gini basado en ordenamiento de predicciones.\n",
    "    Gini = 2 * AUC - 1, donde AUC se calcula como área bajo la curva Lorenz.\n",
    "    \"\"\"\n",
    "    # Ordenar por predicciones\n",
    "    sorted_indices = np.argsort(y_pred)\n",
    "    y_true_sorted = np.array(y_true)[sorted_indices]\n",
    "    \n",
    "    # Calcular proporciones acumuladas\n",
    "    n = len(y_true_sorted)\n",
    "    cumsum_true = np.cumsum(y_true_sorted)\n",
    "    sum_true = cumsum_true[-1]\n",
    "    \n",
    "    # Evitar división por cero\n",
    "    if sum_true == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calcular Gini\n",
    "    gini = (2 * np.sum((np.arange(n) + 1) * y_true_sorted) / (n * sum_true)) - (n + 1) / n\n",
    "    return gini\n",
    "\n",
    "print(\"✓ Función de cálculo de Gini definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MÉTRICAS: MAE Y GINI\n",
      "================================================================================\n",
      "\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  MAE:  $2,829.79\n",
      "  GINI: 0.3432\n",
      "  R²:   0.5474\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  MAE:  $2,597.50\n",
      "  GINI: 0.3495\n",
      "  R²:   0.5300\n",
      "\n",
      "PoissonRegressor:\n",
      "  MAE:  $2,802.44\n",
      "  GINI: 0.3480\n",
      "  R²:   0.4752\n",
      "\n",
      "BaggingRegressor:\n",
      "  MAE:  $2,781.69\n",
      "  GINI: 0.3319\n",
      "  R²:   0.4741\n",
      "\n",
      "HistGradientBoostingRegressor:\n",
      "  MAE:  $2,705.48\n",
      "  GINI: 0.3521\n",
      "  R²:   0.4688\n",
      "\n",
      "LGBMRegressor:\n",
      "  MAE:  $2,686.76\n",
      "  GINI: 0.3470\n",
      "  R²:   0.4671\n",
      "\n",
      "XGBRegressor:\n",
      "  MAE:  $2,820.03\n",
      "  GINI: 0.3144\n",
      "  R²:   0.4602\n",
      "\n",
      "RandomForestRegressor:\n",
      "  MAE:  $2,810.97\n",
      "  GINI: 0.3073\n",
      "  R²:   0.4509\n",
      "\n",
      "OrthogonalMatchingPursuitCV:\n",
      "  MAE:  $2,700.45\n",
      "  GINI: 0.3573\n",
      "  R²:   0.4433\n",
      "\n",
      "Lars:\n",
      "  MAE:  $2,855.81\n",
      "  GINI: 0.3474\n",
      "  R²:   0.4290\n",
      "\n",
      "TransformedTargetRegressor:\n",
      "  MAE:  $2,855.81\n",
      "  GINI: 0.3474\n",
      "  R²:   0.4290\n",
      "\n",
      "LinearRegression:\n",
      "  MAE:  $2,855.81\n",
      "  GINI: 0.3474\n",
      "  R²:   0.4290\n",
      "\n",
      "LassoLars:\n",
      "  MAE:  $2,855.82\n",
      "  GINI: 0.3475\n",
      "  R²:   0.4288\n",
      "\n",
      "Lasso:\n",
      "  MAE:  $2,855.82\n",
      "  GINI: 0.3475\n",
      "  R²:   0.4288\n",
      "\n",
      "Ridge:\n",
      "  MAE:  $2,855.24\n",
      "  GINI: 0.3475\n",
      "  R²:   0.4285\n",
      "\n",
      "LassoCV:\n",
      "  MAE:  $2,855.85\n",
      "  GINI: 0.3475\n",
      "  R²:   0.4283\n",
      "\n",
      "LassoLarsCV:\n",
      "  MAE:  $2,855.86\n",
      "  GINI: 0.3475\n",
      "  R²:   0.4282\n",
      "\n",
      "SGDRegressor:\n",
      "  MAE:  $2,859.41\n",
      "  GINI: 0.3477\n",
      "  R²:   0.4275\n",
      "\n",
      "LarsCV:\n",
      "  MAE:  $2,851.54\n",
      "  GINI: 0.3480\n",
      "  R²:   0.4261\n",
      "\n",
      "RidgeCV:\n",
      "  MAE:  $2,851.08\n",
      "  GINI: 0.3476\n",
      "  R²:   0.4240\n",
      "\n",
      "LassoLarsIC:\n",
      "  MAE:  $2,845.63\n",
      "  GINI: 0.3437\n",
      "  R²:   0.4234\n",
      "\n",
      "BayesianRidge:\n",
      "  MAE:  $2,849.77\n",
      "  GINI: 0.3477\n",
      "  R²:   0.4218\n",
      "\n",
      "ExtraTreesRegressor:\n",
      "  MAE:  $2,982.64\n",
      "  GINI: 0.2701\n",
      "  R²:   0.3974\n",
      "\n",
      "HuberRegressor:\n",
      "  MAE:  $2,814.36\n",
      "  GINI: 0.3477\n",
      "  R²:   0.3682\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  MAE:  $3,158.15\n",
      "  GINI: 0.2693\n",
      "  R²:   0.3565\n",
      "\n",
      "ElasticNet:\n",
      "  MAE:  $2,950.75\n",
      "  GINI: 0.3411\n",
      "  R²:   0.3418\n",
      "\n",
      "PassiveAggressiveRegressor:\n",
      "  MAE:  $2,901.19\n",
      "  GINI: 0.3482\n",
      "  R²:   0.3238\n",
      "\n",
      "ExtraTreeRegressor:\n",
      "  MAE:  $3,195.81\n",
      "  GINI: 0.1979\n",
      "  R²:   0.3111\n",
      "\n",
      "KNeighborsRegressor:\n",
      "  MAE:  $2,887.64\n",
      "  GINI: 0.3278\n",
      "  R²:   0.3009\n",
      "\n",
      "OrthogonalMatchingPursuit:\n",
      "  MAE:  $3,075.79\n",
      "  GINI: 0.2744\n",
      "  R²:   0.2997\n",
      "\n",
      "TweedieRegressor:\n",
      "  MAE:  $3,111.48\n",
      "  GINI: 0.3399\n",
      "  R²:   0.2753\n",
      "\n",
      "GammaRegressor:\n",
      "  MAE:  $3,122.53\n",
      "  GINI: 0.3410\n",
      "  R²:   0.2556\n",
      "\n",
      "ElasticNetCV:\n",
      "  MAE:  $3,309.17\n",
      "  GINI: 0.3373\n",
      "  R²:   0.1920\n",
      "\n",
      "DummyRegressor:\n",
      "  MAE:  $3,850.82\n",
      "  GINI: 0.0398\n",
      "  R²:   -0.0125\n",
      "\n",
      "NuSVR:\n",
      "  MAE:  $3,693.21\n",
      "  GINI: 0.3244\n",
      "  R²:   -0.0725\n",
      "\n",
      "QuantileRegressor:\n",
      "  MAE:  $3,742.06\n",
      "  GINI: 0.0398\n",
      "  R²:   -0.1429\n",
      "\n",
      "SVR:\n",
      "  MAE:  $3,738.63\n",
      "  GINI: 0.3084\n",
      "  R²:   -0.1430\n",
      "\n",
      "RANSACRegressor:\n",
      "  MAE:  $3,773.55\n",
      "  GINI: 0.2629\n",
      "  R²:   -0.2016\n",
      "\n",
      "KernelRidge:\n",
      "  MAE:  $6,102.76\n",
      "  GINI: 0.3475\n",
      "  R²:   -0.6109\n",
      "\n",
      "LinearSVR:\n",
      "  MAE:  $5,580.31\n",
      "  GINI: -0.0870\n",
      "  R²:   -0.9251\n",
      "\n",
      "MLPRegressor:\n",
      "  MAE:  $5,857.49\n",
      "  GINI: 0.3119\n",
      "  R²:   -1.0117\n",
      "\n",
      "GaussianProcessRegressor:\n",
      "  MAE:  $57,743.65\n",
      "  GINI: 0.0938\n",
      "  R²:   -3517.1300\n",
      "\n",
      "================================================================================\n",
      "RESUMEN ORDENADO POR MAE (menor es mejor)\n",
      "================================================================================\n",
      "\n",
      "                       Modelo      MAE  GINI       R²\n",
      "    GradientBoostingRegressor  2597.50  0.35     0.53\n",
      "                LGBMRegressor  2686.76  0.35     0.47\n",
      "  OrthogonalMatchingPursuitCV  2700.45  0.36     0.44\n",
      "HistGradientBoostingRegressor  2705.48  0.35     0.47\n",
      "             BaggingRegressor  2781.69  0.33     0.47\n",
      "             PoissonRegressor  2802.44  0.35     0.48\n",
      "        RandomForestRegressor  2810.97  0.31     0.45\n",
      "               HuberRegressor  2814.36  0.35     0.37\n",
      "                 XGBRegressor  2820.03  0.31     0.46\n",
      "            AdaBoostRegressor  2829.79  0.34     0.55\n",
      "                  LassoLarsIC  2845.63  0.34     0.42\n",
      "                BayesianRidge  2849.77  0.35     0.42\n",
      "                      RidgeCV  2851.08  0.35     0.42\n",
      "                       LarsCV  2851.54  0.35     0.43\n",
      "                        Ridge  2855.24  0.35     0.43\n",
      "             LinearRegression  2855.81  0.35     0.43\n",
      "   TransformedTargetRegressor  2855.81  0.35     0.43\n",
      "                         Lars  2855.81  0.35     0.43\n",
      "                    LassoLars  2855.82  0.35     0.43\n",
      "                        Lasso  2855.82  0.35     0.43\n",
      "                      LassoCV  2855.85  0.35     0.43\n",
      "                  LassoLarsCV  2855.86  0.35     0.43\n",
      "                 SGDRegressor  2859.41  0.35     0.43\n",
      "          KNeighborsRegressor  2887.64  0.33     0.30\n",
      "   PassiveAggressiveRegressor  2901.19  0.35     0.32\n",
      "                   ElasticNet  2950.75  0.34     0.34\n",
      "          ExtraTreesRegressor  2982.64  0.27     0.40\n",
      "    OrthogonalMatchingPursuit  3075.79  0.27     0.30\n",
      "             TweedieRegressor  3111.48  0.34     0.28\n",
      "               GammaRegressor  3122.53  0.34     0.26\n",
      "        DecisionTreeRegressor  3158.15  0.27     0.36\n",
      "           ExtraTreeRegressor  3195.81  0.20     0.31\n",
      "                 ElasticNetCV  3309.17  0.34     0.19\n",
      "                        NuSVR  3693.21  0.32    -0.07\n",
      "                          SVR  3738.63  0.31    -0.14\n",
      "            QuantileRegressor  3742.06  0.04    -0.14\n",
      "              RANSACRegressor  3773.55  0.26    -0.20\n",
      "               DummyRegressor  3850.82  0.04    -0.01\n",
      "                    LinearSVR  5580.31 -0.09    -0.93\n",
      "                 MLPRegressor  5857.49  0.31    -1.01\n",
      "                  KernelRidge  6102.76  0.35    -0.61\n",
      "     GaussianProcessRegressor 57743.65  0.09 -3517.13\n",
      "\n",
      "================================================================================\n",
      "TOP 5 MODELOS POR MAE\n",
      "================================================================================\n",
      "\n",
      "                       Modelo     MAE  GINI   R²\n",
      "    GradientBoostingRegressor 2597.50  0.35 0.53\n",
      "                LGBMRegressor 2686.76  0.35 0.47\n",
      "  OrthogonalMatchingPursuitCV 2700.45  0.36 0.44\n",
      "HistGradientBoostingRegressor 2705.48  0.35 0.47\n",
      "             BaggingRegressor 2781.69  0.33 0.47\n"
     ]
    }
   ],
   "source": [
    "# Calcular MAE y GINI para cada modelo\n",
    "print(\"=\" * 80)\n",
    "print(\"MÉTRICAS: MAE Y GINI\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for model_name in models.index:\n",
    "    # Obtener predicciones del modelo\n",
    "    y_pred = predictions[model_name].values\n",
    "    \n",
    "    # Calcular MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Calcular GINI\n",
    "    gini = gini_coefficient(y_test, y_pred)\n",
    "    \n",
    "    # Obtener R² del LazyPredict\n",
    "    r2 = models.loc[model_name, 'R-Squared']\n",
    "    \n",
    "    resultados.append({\n",
    "        'Modelo': model_name,\n",
    "        'MAE': mae,\n",
    "        'GINI': gini,\n",
    "        'R²': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  MAE:  ${mae:,.2f}\")\n",
    "    print(f\"  GINI: {gini:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Ordenar por MAE (menor es mejor)\n",
    "df_resultados_sorted = df_resultados.sort_values('MAE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN ORDENADO POR MAE (menor es mejor)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(df_resultados_sorted.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP 5 MODELOS POR MAE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(df_resultados_sorted.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## FASE 2: Optimización de Hiperparámetros con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "086a3a53-2167-4bd5-8b63-854bbed31b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELOS SELECCIONADOS PARA OPTIMIZACIÓN (Top 5 por MAE)\n",
      "================================================================================\n",
      "\n",
      "1. GradientBoostingRegressor\n",
      "   MAE: $2,597.50 | GINI: 0.3495 | R²: 0.5300\n",
      "2. LGBMRegressor\n",
      "   MAE: $2,686.76 | GINI: 0.3470 | R²: 0.4671\n",
      "3. OrthogonalMatchingPursuitCV\n",
      "   MAE: $2,700.45 | GINI: 0.3573 | R²: 0.4433\n",
      "4. HistGradientBoostingRegressor\n",
      "   MAE: $2,705.48 | GINI: 0.3521 | R²: 0.4688\n",
      "5. BaggingRegressor\n",
      "   MAE: $2,781.69 | GINI: 0.3319 | R²: 0.4741\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar modelos para optimización (Top 5 por MAE)\n",
    "modelos_a_optimizar = df_resultados_sorted.head(5)['Modelo'].tolist()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELOS SELECCIONADOS PARA OPTIMIZACIÓN (Top 5 por MAE)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "for i, modelo in enumerate(modelos_a_optimizar, 1):\n",
    "    mae = df_resultados_sorted[df_resultados_sorted['Modelo'] == modelo]['MAE'].values[0]\n",
    "    gini = df_resultados_sorted[df_resultados_sorted['Modelo'] == modelo]['GINI'].values[0]\n",
    "    r2 = df_resultados_sorted[df_resultados_sorted['Modelo'] == modelo]['R²'].values[0]\n",
    "    print(f\"{i}. {modelo}\")\n",
    "    print(f\"   MAE: ${mae:,.2f} | GINI: {gini:.4f} | R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a94c5ac-062e-4edc-b174-c3e41c120987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Grillas de hiperparámetros REDUCIDAS definidas con regularización:\n",
      "  - GradientBoostingRegressor: learning_rate, min_samples, subsample, alpha\n",
      "  - LGBMRegressor: reg_alpha/lambda (L1/L2), min_child_samples, subsample\n",
      "  - OrthogonalMatchingPursuitCV: CV con normalización\n",
      "  - HistGradientBoostingRegressor: l2_regularization, min_samples_leaf\n",
      "  - BaggingRegressor: max_samples/features, bootstrap\n",
      "\n",
      "Estimación de combinaciones por modelo:\n",
      "  - GradientBoostingRegressor: 256 = 512 combinaciones\n",
      "  - LGBMRegressor: 768 = 768 combinaciones\n",
      "  - OrthogonalMatchingPursuitCV: 8 = 8 combinaciones\n",
      "  - HistGradientBoostingRegressor: 144 = 288 combinaciones\n",
      "  - BaggingRegressor: 32 = 64 combinaciones\n"
     ]
    }
   ],
   "source": [
    "# Grillas de hiperparámetros reducidas con regularización para evitar overfitting\n",
    "param_grids = {\n",
    "    'GradientBoostingRegressor': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5],\n",
    "        'min_samples_split': [20, 50],\n",
    "        'min_samples_leaf': [10, 20],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'max_features': ['sqrt', None],\n",
    "        'alpha': [0.1, 0.9],  # Cuantil para pérdida (regularización)\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'LGBMRegressor': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5, -1],\n",
    "        'num_leaves': [15, 31],\n",
    "        'min_child_samples': [20, 50],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1],  # L1 regularization\n",
    "        'reg_lambda': [0.1, 1.0],  # L2 regularization\n",
    "        'random_state': [42],\n",
    "        'verbose': [-1]\n",
    "    },\n",
    "    \n",
    "    'OrthogonalMatchingPursuitCV': {\n",
    "        'cv': [3, 5],\n",
    "        'fit_intercept': [True, False],\n",
    "        'normalize': [True, False]\n",
    "    },\n",
    "    \n",
    "    'HistGradientBoostingRegressor': {\n",
    "        'max_iter': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5, None],\n",
    "        'min_samples_leaf': [20, 50],\n",
    "        'l2_regularization': [0.0, 0.1, 1.0],  # Regularización L2\n",
    "        'max_leaf_nodes': [31, None],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'BaggingRegressor': {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_samples': [0.7, 1.0],\n",
    "        'max_features': [0.7, 1.0],\n",
    "        'bootstrap': [True, False],\n",
    "        'bootstrap_features': [True, False],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_mapping = {\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'LGBMRegressor': LGBMRegressor(verbose=-1),\n",
    "    'OrthogonalMatchingPursuitCV': OrthogonalMatchingPursuitCV(),\n",
    "    'HistGradientBoostingRegressor': HistGradientBoostingRegressor(),\n",
    "    'BaggingRegressor': BaggingRegressor()\n",
    "}\n",
    "\n",
    "print(\"✓ Grillas de hiperparámetros REDUCIDAS definidas con regularización:\")\n",
    "print(\"  - GradientBoostingRegressor: learning_rate, min_samples, subsample, alpha\")\n",
    "print(\"  - LGBMRegressor: reg_alpha/lambda (L1/L2), min_child_samples, subsample\")\n",
    "print(\"  - OrthogonalMatchingPursuitCV: CV con normalización\")\n",
    "print(\"  - HistGradientBoostingRegressor: l2_regularization, min_samples_leaf\")\n",
    "print(\"  - BaggingRegressor: max_samples/features, bootstrap\")\n",
    "print()\n",
    "print(\"Estimación de combinaciones por modelo:\")\n",
    "print(f\"  - GradientBoostingRegressor: {2*2*2*2*2*2*2*2*1} = 512 combinaciones\")\n",
    "print(f\"  - LGBMRegressor: {2*2*3*2*2*2*2*2*2*1*1} = 768 combinaciones\")\n",
    "print(f\"  - OrthogonalMatchingPursuitCV: {2*2*2} = 8 combinaciones\")\n",
    "print(f\"  - HistGradientBoostingRegressor: {2*2*3*2*3*2*1} = 288 combinaciones\")\n",
    "print(f\"  - BaggingRegressor: {2*2*2*2*2*1} = 64 combinaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6615409b-b4bb-4a8e-b1f2-8b19c1193a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID SEARCH CON VALIDACIÓN CRUZADA (optimizando MAE)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "[1/5] Optimizando: GradientBoostingRegressor\n",
      "================================================================================\n",
      "Combinaciones: 256 | Total fits: 1280\n",
      "✓ MAE CV: $2,542.14\n",
      "Mejores parámetros: {'alpha': 0.1, 'learning_rate': 0.05, 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 20, 'min_samples_split': 20, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.8}\n",
      "\n",
      "================================================================================\n",
      "[2/5] Optimizando: LGBMRegressor\n",
      "================================================================================\n",
      "Combinaciones: 768 | Total fits: 3840\n",
      "✓ MAE CV: $2,556.60\n",
      "Mejores parámetros: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 15, 'random_state': 42, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 0.8, 'verbose': -1}\n",
      "\n",
      "================================================================================\n",
      "[3/5] Optimizando: OrthogonalMatchingPursuitCV\n",
      "================================================================================\n",
      "Combinaciones: 8 | Total fits: 40\n",
      "✗ Error: Invalid parameter 'normalize' for estimator OrthogonalMatchingPursuitCV(cv=3). Valid parameters are: ['copy', 'cv', 'fit_intercept', 'max_iter', 'n_jobs', 'verbose'].\n",
      "\n",
      "================================================================================\n",
      "[4/5] Optimizando: HistGradientBoostingRegressor\n",
      "================================================================================\n",
      "Combinaciones: 144 | Total fits: 720\n",
      "✓ MAE CV: $2,553.40\n",
      "Mejores parámetros: {'l2_regularization': 0.1, 'learning_rate': 0.05, 'max_depth': 3, 'max_iter': 100, 'max_leaf_nodes': 31, 'min_samples_leaf': 20, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "[5/5] Optimizando: BaggingRegressor\n",
      "================================================================================\n",
      "Combinaciones: 32 | Total fits: 160\n",
      "✓ MAE CV: $2,527.89\n",
      "Mejores parámetros: {'bootstrap': False, 'bootstrap_features': False, 'max_features': 0.7, 'max_samples': 0.7, 'n_estimators': 100, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "Completado: 4/5 modelos\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV con validación cruzada\n",
    "print(\"=\" * 80)\n",
    "print(\"GRID SEARCH CON VALIDACIÓN CRUZADA (optimizando MAE)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "optimized_models = {}\n",
    "grid_results = {}\n",
    "\n",
    "for i, model_name in enumerate(modelos_a_optimizar, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"[{i}/{len(modelos_a_optimizar)}] Optimizando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if model_name not in param_grids or model_name not in model_mapping:\n",
    "        print(f\"⚠ No hay grilla para {model_name}, saltando...\")\n",
    "        continue\n",
    "    \n",
    "    base_model = model_mapping[model_name]\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    n_combinations = np.prod([len(v) if isinstance(v, list) else 1 for v in param_grid.values()])\n",
    "    print(f\"Combinaciones: {int(n_combinations)} | Total fits: {int(5 * n_combinations)}\")\n",
    "    \n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=mae_scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_selected, y_train)\n",
    "        \n",
    "        optimized_models[model_name] = grid_search.best_estimator_\n",
    "        grid_results[model_name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score_cv': -grid_search.best_score_  # Negar porque MAE es negativo en GridSearch\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ MAE CV: ${-grid_search.best_score_:,.2f}\")\n",
    "        print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Completado: {len(optimized_models)}/{len(modelos_a_optimizar)} modelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af2d5e38-0474-4d66-8990-ec0f98d8ceb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Función de R² ajustado definida\n"
     ]
    }
   ],
   "source": [
    "# Función para calcular R² ajustado\n",
    "def adjusted_r2(y_true, y_pred, n, p):\n",
    "    \"\"\"\n",
    "    Calcula el R² ajustado.\n",
    "    n: número de observaciones\n",
    "    p: número de predictores\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    return adj_r2\n",
    "\n",
    "print(\"✓ Función de R² ajustado definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f4adcc2-6ab8-4c59-b0c7-6895591dda66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACIÓN EN TEST SET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Evaluando: GradientBoostingRegressor\n",
      "================================================================================\n",
      "MAE CV:  $2,542.14\n",
      "MAE Test: $2,687.61\n",
      "R²:       0.4710\n",
      "R² adj:   0.3986\n",
      "GINI:     0.3552\n",
      "\n",
      "Mejores parámetros:\n",
      "  alpha: 0.1\n",
      "  learning_rate: 0.05\n",
      "  max_depth: 3\n",
      "  max_features: None\n",
      "  min_samples_leaf: 20\n",
      "  min_samples_split: 20\n",
      "  n_estimators: 100\n",
      "  random_state: 42\n",
      "  subsample: 0.8\n",
      "\n",
      "================================================================================\n",
      "Evaluando: LGBMRegressor\n",
      "================================================================================\n",
      "MAE CV:  $2,556.60\n",
      "MAE Test: $2,740.56\n",
      "R²:       0.4420\n",
      "R² adj:   0.3656\n",
      "GINI:     0.3473\n",
      "\n",
      "Mejores parámetros:\n",
      "  colsample_bytree: 0.8\n",
      "  learning_rate: 0.05\n",
      "  max_depth: 5\n",
      "  min_child_samples: 20\n",
      "  n_estimators: 100\n",
      "  num_leaves: 15\n",
      "  random_state: 42\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 0.1\n",
      "  subsample: 0.8\n",
      "  verbose: -1\n",
      "\n",
      "================================================================================\n",
      "Evaluando: HistGradientBoostingRegressor\n",
      "================================================================================\n",
      "MAE CV:  $2,553.40\n",
      "MAE Test: $2,676.10\n",
      "R²:       0.4510\n",
      "R² adj:   0.3758\n",
      "GINI:     0.3567\n",
      "\n",
      "Mejores parámetros:\n",
      "  l2_regularization: 0.1\n",
      "  learning_rate: 0.05\n",
      "  max_depth: 3\n",
      "  max_iter: 100\n",
      "  max_leaf_nodes: 31\n",
      "  min_samples_leaf: 20\n",
      "  random_state: 42\n",
      "\n",
      "================================================================================\n",
      "Evaluando: BaggingRegressor\n",
      "================================================================================\n",
      "MAE CV:  $2,527.89\n",
      "MAE Test: $2,785.14\n",
      "R²:       0.4285\n",
      "R² adj:   0.3502\n",
      "GINI:     0.3434\n",
      "\n",
      "Mejores parámetros:\n",
      "  bootstrap: False\n",
      "  bootstrap_features: False\n",
      "  max_features: 0.7\n",
      "  max_samples: 0.7\n",
      "  n_estimators: 100\n",
      "  random_state: 42\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "                       Modelo  MAE_CV  MAE_Test   R²  R²_adj  GINI\n",
      "HistGradientBoostingRegressor 2553.40   2676.10 0.45    0.38  0.36\n",
      "    GradientBoostingRegressor 2542.14   2687.61 0.47    0.40  0.36\n",
      "                LGBMRegressor 2556.60   2740.56 0.44    0.37  0.35\n",
      "             BaggingRegressor 2527.89   2785.14 0.43    0.35  0.34\n"
     ]
    }
   ],
   "source": [
    "# Evaluación en test set\n",
    "print(\"=\" * 80)\n",
    "print(\"EVALUACIÓN EN TEST SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_results = []\n",
    "n_test = len(y_test)\n",
    "p_test = X_test_selected.shape[1]\n",
    "\n",
    "for model_name, model in optimized_models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # Métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    adj_r2 = adjusted_r2(y_test, y_pred, n_test, p_test)\n",
    "    gini = gini_coefficient(y_test, y_pred)\n",
    "    \n",
    "    test_results.append({\n",
    "        'Modelo': model_name,\n",
    "        'MAE_CV': grid_results[model_name]['best_score_cv'],\n",
    "        'MAE_Test': mae,\n",
    "        'R²': r2,\n",
    "        'R²_adj': adj_r2,\n",
    "        'GINI': gini\n",
    "    })\n",
    "    \n",
    "    print(f\"MAE CV:  ${grid_results[model_name]['best_score_cv']:,.2f}\")\n",
    "    print(f\"MAE Test: ${mae:,.2f}\")\n",
    "    print(f\"R²:       {r2:.4f}\")\n",
    "    print(f\"R² adj:   {adj_r2:.4f}\")\n",
    "    print(f\"GINI:     {gini:.4f}\")\n",
    "    print(f\"\\nMejores parámetros:\")\n",
    "    for param, value in grid_results[model_name]['best_params'].items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "df_test_results = pd.DataFrame(test_results).sort_values('MAE_Test')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESUMEN DE RESULTADOS\")\n",
    "print(f\"{'='*80}\")\n",
    "print()\n",
    "print(df_test_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset completo: (416, 10)\n",
      "Severidad promedio: $5391.41\n",
      "\n",
      "Mejores parámetros:\n",
      "  alpha: 0.1\n",
      "  learning_rate: 0.05\n",
      "  max_depth: 3\n",
      "  max_features: None\n",
      "  min_samples_leaf: 20\n",
      "  min_samples_split: 20\n",
      "  n_estimators: 100\n",
      "  random_state: 42\n",
      "  subsample: 0.8\n",
      "\n",
      "================================================================================\n",
      "MODELO EXPORTADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "Ruta: ../models/severidad_adicionales.pkl\n",
      "Modelo: GradientBoostingRegressor\n",
      "Entrenado con: 416 registros\n",
      "\n",
      "Métricas en Test Set:\n",
      "  MAE:$2,687.61\n",
      "  R²: 0.4710\n",
      "  R² adj: 0.3986\n",
      "  GINI: 0.3552\n"
     ]
    }
   ],
   "source": [
    "  import pickle\n",
    "  import os\n",
    "\n",
    "  # Crear directorio models si no existe\n",
    "  os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "  # Combinar train y test para entrenar con todo el dataset\n",
    "  X_full = pd.concat([X_train_selected, X_test_selected])\n",
    "  y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "  print(f\"Dataset completo: {X_full.shape}\")\n",
    "  print(f\"Severidad promedio: ${y_full.mean():.2f}\")\n",
    "\n",
    "  # Obtener los mejores parámetros del\n",
    "  GradientBoostingRegressor\n",
    "  best_params_gbr = grid_results['GradientBoostingRegressor']['best_params']\n",
    "  print(f\"\\nMejores parámetros:\")\n",
    "  for param, value in best_params_gbr.items():\n",
    "      print(f\"  {param}: {value}\")\n",
    "\n",
    "  # Crear y entrenar modelo con todos los datos\n",
    "  gbr_final =GradientBoostingRegressor(**best_params_gbr)\n",
    "  gbr_final.fit(X_full, y_full)\n",
    "\n",
    "  # Preparar objeto para exportar\n",
    "  modelo_export = {\n",
    "      'modelo': gbr_final,\n",
    "      'preprocessor': preprocessor,\n",
    "      'features_seleccionadas': final_selected_features,\n",
    "      'metricas': {\n",
    "          'MAE_CV': grid_results['GradientBoostingRegressor']['best_score_cv'],\n",
    "          'MAE_Test':\n",
    "  df_test_results[df_test_results['Modelo'] =='GradientBoostingRegressor']['MAE_Test'].values[0],\n",
    "  'R²': df_test_results[df_test_results['Modelo'] == 'GradientBoostingRegressor']['R²'].values[0],\n",
    "          'R²_adj': df_test_results[df_test_results['Modelo'] ==\n",
    "  'GradientBoostingRegressor']['R²_adj'].values[0],\n",
    "          'GINI':\n",
    "  df_test_results[df_test_results['Modelo'] == 'GradientBoostingRegressor']['GINI'].values[0]\n",
    "      },\n",
    "      'mejores_parametros': best_params_gbr\n",
    "  }\n",
    "\n",
    "  # Exportar modelo\n",
    "  model_path = '../models/severidad_adicionales.pkl'\n",
    "  with open(model_path, 'wb') as f:\n",
    "      pickle.dump(modelo_export, f)\n",
    "\n",
    "  print(f\"\\n{'='*80}\")\n",
    "  print(\"MODELO EXPORTADO EXITOSAMENTE\")\n",
    "  print(f\"{'='*80}\")\n",
    "  print(f\"\\nRuta: {model_path}\")\n",
    "  print(f\"Modelo: GradientBoostingRegressor\")\n",
    "  print(f\"Entrenado con: {len(X_full)} registros\")\n",
    "  print(f\"\\nMétricas en Test Set:\")\n",
    "  print(f\"  MAE:${modelo_export['metricas']['MAE_Test']:,.2f}\")\n",
    "  print(f\"  R²: {modelo_export['metricas']['R²']:.4f}\")\n",
    "  print(f\"  R² adj: {modelo_export['metricas']['R²_adj']:.4f}\")\n",
    "  print(f\"  GINI: {modelo_export['metricas']['GINI']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competencia_cas_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
