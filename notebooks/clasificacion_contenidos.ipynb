{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Modelo de Clasificaci√≥n - Contenidos\n",
    "\n",
    "## Objetivo\n",
    "Predecir si un asegurado presentar√° siniestros en la cobertura de Contenidos (clasificaci√≥n binaria).\n",
    "\n",
    "## Pipeline\n",
    "1. **Fase 1**: Preprocesamiento + GLM + LazyPredict\n",
    "2. **Fase 2**: Optimizaci√≥n de top 5 modelos con GridSearchCV\n",
    "3. **Fase 3**: Evaluaci√≥n y selecci√≥n del mejor modelo\n",
    "\n",
    "**Dataset**: Por determinar | Desbalanceo: Por calcular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Manipulaci√≥n de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, make_scorer\n",
    ")\n",
    "\n",
    "# LazyPredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Selecci√≥n de variables\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuraci√≥n\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original: (7999, 9)\n",
      "\n",
      "Columnas: ['a√±o_cursado', 'estudios_area', 'calif_promedio', '2_o_mas_inquilinos', 'distancia_al_campus', 'genero', 'extintor_incendios', 'Contenidos_siniestros_num', 'Contenidos_siniestros_monto']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a√±o_cursado</th>\n",
       "      <th>estudios_area</th>\n",
       "      <th>calif_promedio</th>\n",
       "      <th>2_o_mas_inquilinos</th>\n",
       "      <th>distancia_al_campus</th>\n",
       "      <th>genero</th>\n",
       "      <th>extintor_incendios</th>\n",
       "      <th>Contenidos_siniestros_num</th>\n",
       "      <th>Contenidos_siniestros_monto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3er a√±o</td>\n",
       "      <td>Humanidades</td>\n",
       "      <td>3.01</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3er a√±o</td>\n",
       "      <td>Ciencias</td>\n",
       "      <td>1.52</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3er a√±o</td>\n",
       "      <td>Administracion</td>\n",
       "      <td>7.68</td>\n",
       "      <td>No</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4to a√±o</td>\n",
       "      <td>Administracion</td>\n",
       "      <td>8.06</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2do a√±o</td>\n",
       "      <td>Administracion</td>\n",
       "      <td>6.72</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  a√±o_cursado   estudios_area  calif_promedio 2_o_mas_inquilinos  \\\n",
       "0     3er a√±o     Humanidades            3.01                 No   \n",
       "1     3er a√±o        Ciencias            1.52                 No   \n",
       "2     3er a√±o  Administracion            7.68                 No   \n",
       "3     4to a√±o  Administracion            8.06                 No   \n",
       "4     2do a√±o  Administracion            6.72                 No   \n",
       "\n",
       "   distancia_al_campus     genero extintor_incendios  \\\n",
       "0                 0.00  Masculino                 Si   \n",
       "1                 0.00   Femenino                 Si   \n",
       "2                 0.22   Femenino                 No   \n",
       "3                 0.00  Masculino                 No   \n",
       "4                 0.00   Femenino                 No   \n",
       "\n",
       "   Contenidos_siniestros_num  Contenidos_siniestros_monto  \n",
       "0                       0.00                         0.00  \n",
       "1                       0.00                         0.00  \n",
       "2                       0.00                         0.00  \n",
       "3                       0.00                         0.00  \n",
       "4                       0.00                         0.00  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv(\"../data/processed/contenidos_full.csv\")\n",
    "\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "print(f\"\\nColumnas: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset preparado: (7999, 8)\n",
      "\n",
      "Distribuci√≥n variable objetivo:\n",
      "siniestrado\n",
      "0    7256\n",
      "1     743\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentaje siniestrados: 9.29%\n",
      "Desbalanceo: 9.8:1\n"
     ]
    }
   ],
   "source": [
    "# Eliminar columna de monto (no se usa en clasificaci√≥n)\n",
    "df = df.drop('Contenidos_siniestros_monto', axis=1)\n",
    "\n",
    "# Crear variable binaria objetivo: 0 si no siniestr√≥, 1 si siniestr√≥\n",
    "df['siniestrado'] = (df['Contenidos_siniestros_num'] > 0).astype(int)\n",
    "\n",
    "# Eliminar columna original de n√∫mero de siniestros\n",
    "df = df.drop('Contenidos_siniestros_num', axis=1)\n",
    "\n",
    "print(f\"\\nDataset preparado: {df.shape}\")\n",
    "print(f\"\\nDistribuci√≥n variable objetivo:\")\n",
    "print(df['siniestrado'].value_counts())\n",
    "print(f\"\\nPorcentaje siniestrados: {df['siniestrado'].mean()*100:.2f}%\")\n",
    "print(f\"Desbalanceo: {df['siniestrado'].value_counts()[0] / df['siniestrado'].value_counts()[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio R√°pido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables num√©ricas: ['calif_promedio', 'distancia_al_campus']\n",
      "Variables categ√≥ricas: ['a√±o_cursado', 'estudios_area', '2_o_mas_inquilinos', 'genero', 'extintor_incendios']\n",
      "\n",
      "Total features: 7\n",
      "\n",
      "Valores faltantes:\n",
      "a√±o_cursado            0\n",
      "estudios_area          0\n",
      "calif_promedio         0\n",
      "2_o_mas_inquilinos     0\n",
      "distancia_al_campus    0\n",
      "genero                 0\n",
      "extintor_incendios     0\n",
      "siniestrado            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificar tipos de variables\n",
    "numeric_features = ['calif_promedio', 'distancia_al_campus']\n",
    "categorical_features = ['a√±o_cursado', 'estudios_area', '2_o_mas_inquilinos', 'genero', 'extintor_incendios']\n",
    "\n",
    "print(\"Variables num√©ricas:\", numeric_features)\n",
    "print(\"Variables categ√≥ricas:\", categorical_features)\n",
    "print(f\"\\nTotal features: {len(numeric_features) + len(categorical_features)}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"\\nValores faltantes:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTAD√çSTICAS DESCRIPTIVAS POR CLASE\n",
      "================================================================================\n",
      "\n",
      "a√±o_cursado:\n",
      "siniestrado     0     1\n",
      "a√±o_cursado            \n",
      "1er a√±o     89.57 10.43\n",
      "2do a√±o     89.81 10.19\n",
      "3er a√±o     90.48  9.52\n",
      "4to a√±o     92.04  7.96\n",
      "posgrado    92.70  7.30\n",
      "\n",
      "estudios_area:\n",
      "siniestrado        0     1\n",
      "estudios_area             \n",
      "Administracion 89.85 10.15\n",
      "Ciencias       90.49  9.51\n",
      "Humanidades    91.38  8.62\n",
      "Otro           91.16  8.84\n",
      "\n",
      "2_o_mas_inquilinos:\n",
      "siniestrado            0     1\n",
      "2_o_mas_inquilinos            \n",
      "No                 92.39  7.61\n",
      "Si                 83.78 16.22\n",
      "\n",
      "genero:\n",
      "siniestrado      0     1\n",
      "genero                  \n",
      "Femenino     91.03  8.97\n",
      "Masculino    90.41  9.59\n",
      "No respuesta 88.35 11.65\n",
      "Otro         91.73  8.27\n",
      "\n",
      "extintor_incendios:\n",
      "siniestrado            0    1\n",
      "extintor_incendios           \n",
      "No                 91.17 8.83\n",
      "Si                 90.52 9.48\n"
     ]
    }
   ],
   "source": [
    "# Estad√≠sticas descriptivas por clase\n",
    "print(\"=\" * 80)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS POR CLASE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for var in categorical_features:\n",
    "    print(f\"\\n{var}:\")\n",
    "    tabla = pd.crosstab(df[var], df['siniestrado'], normalize='index') * 100\n",
    "    print(tabla.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento y Split de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (6399, 7) | Siniestrados: 594 (9.28%)\n",
      "Test set:  (1600, 7) | Siniestrados: 149 (9.31%)\n"
     ]
    }
   ],
   "source": [
    "# Separar features y target\n",
    "X = df.drop('siniestrado', axis=1)\n",
    "y = df['siniestrado']\n",
    "\n",
    "# Split train/test estratificado 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape} | Siniestrados: {y_train.sum()} ({y_train.mean()*100:.2f}%)\")\n",
    "print(f\"Test set:  {X_test.shape} | Siniestrados: {y_test.sum()} ({y_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features despu√©s de preprocesamiento: 14\n",
      "Shape X_train: (6399, 14)\n",
      "Shape X_test: (1600, 14)\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Ajustar y transformar datos\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Obtener nombres de features despu√©s de one-hot encoding\n",
    "feature_names_num = numeric_features\n",
    "feature_names_cat = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "feature_names = list(feature_names_num) + list(feature_names_cat)\n",
    "\n",
    "# Convertir a DataFrame (mantener √≠ndices originales para alinear con y_train/y_test)\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "print(f\"\\nFeatures despu√©s de preprocesamiento: {len(feature_names)}\")\n",
    "print(f\"Shape X_train: {X_train_df.shape}\")\n",
    "print(f\"Shape X_test: {X_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Fase 1 - GLM con Selecci√≥n Backward de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELO LOG√çSTICO COMPLETO (todas las variables)\n",
      "================================================================================\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            siniestrado   No. Observations:                 6399\n",
      "Model:                          Logit   Df Residuals:                     6384\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Thu, 09 Oct 2025   Pseudo R-squ.:                 0.03057\n",
      "Time:                        22:56:16   Log-Likelihood:                -1917.0\n",
      "converged:                       True   LL-Null:                       -1977.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.210e-19\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.3266      0.143    -16.247      0.000      -2.607      -2.046\n",
      "calif_promedio               -0.0665      0.043     -1.538      0.124      -0.151       0.018\n",
      "distancia_al_campus           0.0833      0.040      2.069      0.039       0.004       0.162\n",
      "a√±o_cursado_2do a√±o           0.0430      0.122      0.354      0.723      -0.195       0.281\n",
      "a√±o_cursado_3er a√±o          -0.1118      0.127     -0.882      0.378      -0.360       0.137\n",
      "a√±o_cursado_4to a√±o          -0.3172      0.132     -2.409      0.016      -0.575      -0.059\n",
      "a√±o_cursado_posgrado         -0.5684      0.184     -3.090      0.002      -0.929      -0.208\n",
      "estudios_area_Ciencias       -0.0585      0.119     -0.491      0.623      -0.292       0.175\n",
      "estudios_area_Humanidades    -0.2311      0.124     -1.867      0.062      -0.474       0.012\n",
      "estudios_area_Otro           -0.1464      0.122     -1.198      0.231      -0.386       0.093\n",
      "2_o_mas_inquilinos_Si         0.9207      0.093      9.906      0.000       0.739       1.103\n",
      "genero_Masculino              0.0848      0.092      0.924      0.356      -0.095       0.265\n",
      "genero_No respuesta           0.2884      0.239      1.209      0.227      -0.179       0.756\n",
      "genero_Otro                  -0.0205      0.188     -0.109      0.913      -0.389       0.349\n",
      "extintor_incendios_Si        -0.0132      0.095     -0.138      0.890      -0.200       0.173\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Modelo log√≠stico completo para referencia\n",
    "X_train_const = sm.add_constant(X_train_df)\n",
    "logit_full = sm.Logit(y_train, X_train_const)\n",
    "result_full = logit_full.fit(disp=0)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELO LOG√çSTICO COMPLETO (todas las variables)\")\n",
    "print(\"=\" * 80)\n",
    "print(result_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SELECCI√ìN BACKWARD DE VARIABLES (Œ± = 0.1)\n",
      "================================================================================\n",
      "\n",
      "Eliminando: genero_Otro (p-valor: 0.9135)\n",
      "Eliminando: extintor_incendios_Si (p-valor: 0.8911)\n",
      "Eliminando: a√±o_cursado_2do a√±o (p-valor: 0.7256)\n",
      "Eliminando: estudios_area_Ciencias (p-valor: 0.6211)\n",
      "Eliminando: genero_Masculino (p-valor: 0.3242)\n",
      "Eliminando: genero_No respuesta (p-valor: 0.2815)\n",
      "Eliminando: estudios_area_Otro (p-valor: 0.2702)\n",
      "Eliminando: a√±o_cursado_3er a√±o (p-valor: 0.2436)\n",
      "Eliminando: calif_promedio (p-valor: 0.1282)\n",
      "Eliminando: estudios_area_Humanidades (p-valor: 0.1053)\n",
      "\n",
      "================================================================================\n",
      "VARIABLES SELECCIONADAS: 4\n",
      "================================================================================\n",
      "  ‚Ä¢ distancia_al_campus\n",
      "  ‚Ä¢ a√±o_cursado_4to a√±o\n",
      "  ‚Ä¢ a√±o_cursado_posgrado\n",
      "  ‚Ä¢ 2_o_mas_inquilinos_Si\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            siniestrado   No. Observations:                 6399\n",
      "Model:                          Logit   Df Residuals:                     6394\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 09 Oct 2025   Pseudo R-squ.:                 0.02802\n",
      "Time:                        22:56:17   Log-Likelihood:                -1922.1\n",
      "converged:                       True   LL-Null:                       -1977.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.836e-23\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    -2.4120      0.059    -40.680      0.000      -2.528      -2.296\n",
      "distancia_al_campus       0.0820      0.040      2.042      0.041       0.003       0.161\n",
      "a√±o_cursado_4to a√±o      -0.2944      0.111     -2.644      0.008      -0.513      -0.076\n",
      "a√±o_cursado_posgrado     -0.5507      0.170     -3.238      0.001      -0.884      -0.217\n",
      "2_o_mas_inquilinos_Si     0.9184      0.093      9.915      0.000       0.737       1.100\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Selecci√≥n Backward basada en p-valores\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Realiza selecci√≥n backward de variables basada en p-valores del GLM.\n",
    "    \"\"\"\n",
    "    features = list(X.columns)\n",
    "    \n",
    "    while True:\n",
    "        X_const = sm.add_constant(X[features])\n",
    "        model = sm.Logit(y, X_const).fit(disp=0)\n",
    "        p_values = model.pvalues.iloc[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value <= significance_level:\n",
    "            break\n",
    "            \n",
    "        feature_to_remove = p_values.idxmax()\n",
    "        features.remove(feature_to_remove)\n",
    "        print(f\"Eliminando: {feature_to_remove} (p-valor: {max_p_value:.4f})\")\n",
    "    \n",
    "    return features, model\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SELECCI√ìN BACKWARD DE VARIABLES (Œ± = 0.1)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "selected_features, logit_backward = backward_elimination(X_train_df, y_train, significance_level=0.1)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(f\"VARIABLES SELECCIONADAS: {len(selected_features)}\")\n",
    "print(\"=\" * 80)\n",
    "for feat in selected_features:\n",
    "    print(f\"  ‚Ä¢ {feat}\")\n",
    "print()\n",
    "print(logit_backward.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES FINALES (con todos los niveles de categ√≥ricas)\n",
      "================================================================================\n",
      "\n",
      "Total features: 6\n",
      "\n",
      "Features seleccionadas:\n",
      "  ‚úì 2_o_mas_inquilinos_Si\n",
      "  + a√±o_cursado_2do a√±o\n",
      "  + a√±o_cursado_3er a√±o\n",
      "  ‚úì a√±o_cursado_4to a√±o\n",
      "  ‚úì a√±o_cursado_posgrado\n",
      "  ‚úì distancia_al_campus\n",
      "\n",
      "Shape final - Train: (6399, 6) | Test: (1600, 6)\n"
     ]
    }
   ],
   "source": [
    "# Expandir variables categ√≥ricas completas\n",
    "def expand_categorical_features(selected_features, all_feature_names, categorical_features):\n",
    "    selected_cat_vars = set()\n",
    "    for feat in selected_features:\n",
    "        for cat_var in categorical_features:\n",
    "            if feat.startswith(cat_var + '_'):\n",
    "                selected_cat_vars.add(cat_var)\n",
    "                break\n",
    "    \n",
    "    final_features = []\n",
    "    for feat in selected_features:\n",
    "        is_categorical = any(feat.startswith(cat_var + '_') for cat_var in categorical_features)\n",
    "        if not is_categorical:\n",
    "            final_features.append(feat)\n",
    "    \n",
    "    for feat in all_feature_names:\n",
    "        for cat_var in selected_cat_vars:\n",
    "            if feat.startswith(cat_var + '_') and feat not in final_features:\n",
    "                final_features.append(feat)\n",
    "                break\n",
    "    \n",
    "    return sorted(final_features)\n",
    "\n",
    "final_selected_features = expand_categorical_features(selected_features, feature_names, categorical_features)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURES FINALES (con todos los niveles de categ√≥ricas)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features: {len(final_selected_features)}\")\n",
    "print(\"\\nFeatures seleccionadas:\")\n",
    "for feat in final_selected_features:\n",
    "    indicator = \"‚úì\" if feat in selected_features else \"+\"\n",
    "    print(f\"  {indicator} {feat}\")\n",
    "\n",
    "X_train_selected = X_train_df[final_selected_features]\n",
    "X_test_selected = X_test_df[final_selected_features]\n",
    "\n",
    "print(f\"\\nShape final - Train: {X_train_selected.shape} | Test: {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Fase 1 - LazyPredict para Identificar Mejores Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EJECUTANDO LAZYPREDICT\n",
      "================================================================================\n",
      "\n",
      "Dataset: 6399 muestras, 6 features\n",
      "Esto puede tomar varios minutos...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc06a12f18c4462bf97e4f2a6bd197a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTADOS DE LAZYPREDICT\n",
      "================================================================================\n",
      "\n",
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "NearestCentroid                    0.73               0.55     0.55      0.78   \n",
      "Perceptron                         0.79               0.52     0.52      0.81   \n",
      "ExtraTreeClassifier                0.89               0.52     0.52      0.86   \n",
      "DecisionTreeClassifier             0.88               0.51     0.51      0.86   \n",
      "BaggingClassifier                  0.89               0.51     0.51      0.86   \n",
      "RandomForestClassifier             0.88               0.51     0.51      0.86   \n",
      "LGBMClassifier                     0.91               0.51     0.51      0.86   \n",
      "ExtraTreesClassifier               0.88               0.51     0.51      0.85   \n",
      "LabelPropagation                   0.91               0.50     0.50      0.86   \n",
      "LabelSpreading                     0.91               0.50     0.50      0.86   \n",
      "GaussianNB                         0.90               0.50     0.50      0.86   \n",
      "PassiveAggressiveClassifier        0.91               0.50     0.50      0.86   \n",
      "CalibratedClassifierCV             0.91               0.50     0.50      0.86   \n",
      "CategoricalNB                      0.91               0.50     0.50      0.86   \n",
      "DummyClassifier                    0.91               0.50     0.50      0.86   \n",
      "AdaBoostClassifier                 0.91               0.50     0.50      0.86   \n",
      "BernoulliNB                        0.91               0.50     0.50      0.86   \n",
      "LinearSVC                          0.91               0.50     0.50      0.86   \n",
      "LinearDiscriminantAnalysis         0.91               0.50     0.50      0.86   \n",
      "SVC                                0.91               0.50     0.50      0.86   \n",
      "LogisticRegression                 0.91               0.50     0.50      0.86   \n",
      "RidgeClassifierCV                  0.91               0.50     0.50      0.86   \n",
      "RidgeClassifier                    0.91               0.50     0.50      0.86   \n",
      "SGDClassifier                      0.91               0.50     0.50      0.86   \n",
      "KNeighborsClassifier               0.90               0.50     0.50      0.86   \n",
      "QuadraticDiscriminantAnalysis      0.90               0.50     0.50      0.86   \n",
      "XGBClassifier                      0.90               0.50     0.50      0.86   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "NearestCentroid                      0.01  \n",
      "Perceptron                           0.01  \n",
      "ExtraTreeClassifier                  0.01  \n",
      "DecisionTreeClassifier               0.02  \n",
      "BaggingClassifier                    0.05  \n",
      "RandomForestClassifier               0.22  \n",
      "LGBMClassifier                       0.07  \n",
      "ExtraTreesClassifier                 0.19  \n",
      "LabelPropagation                     0.54  \n",
      "LabelSpreading                       0.94  \n",
      "GaussianNB                           0.01  \n",
      "PassiveAggressiveClassifier          0.01  \n",
      "CalibratedClassifierCV               0.03  \n",
      "CategoricalNB                        0.01  \n",
      "DummyClassifier                      0.01  \n",
      "AdaBoostClassifier                   0.11  \n",
      "BernoulliNB                          0.01  \n",
      "LinearSVC                            0.01  \n",
      "LinearDiscriminantAnalysis           0.01  \n",
      "SVC                                  0.30  \n",
      "LogisticRegression                   0.01  \n",
      "RidgeClassifierCV                    0.01  \n",
      "RidgeClassifier                      0.01  \n",
      "SGDClassifier                        0.02  \n",
      "KNeighborsClassifier                 0.03  \n",
      "QuadraticDiscriminantAnalysis        0.01  \n",
      "XGBClassifier                        0.07  \n"
     ]
    }
   ],
   "source": [
    "# Ejecutar LazyPredict\n",
    "print(\"=\" * 80)\n",
    "print(\"EJECUTANDO LAZYPREDICT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: {X_train_selected.shape[0]} muestras, {X_train_selected.shape[1]} features\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, predictions=True, random_state=42)\n",
    "models, predictions = clf.fit(X_train_selected, X_test_selected, y_train, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESULTADOS DE LAZYPREDICT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## Top 5 Modelos por F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 5 MODELOS POR F1-SCORE\n",
      "================================================================================\n",
      "\n",
      "                             Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                         \n",
      "LGBMClassifier                   0.91               0.51     0.51      0.86   \n",
      "LabelPropagation                 0.91               0.50     0.50      0.86   \n",
      "LabelSpreading                   0.91               0.50     0.50      0.86   \n",
      "PassiveAggressiveClassifier      0.91               0.50     0.50      0.86   \n",
      "CalibratedClassifierCV           0.91               0.50     0.50      0.86   \n",
      "\n",
      "                             Time Taken  \n",
      "Model                                    \n",
      "LGBMClassifier                     0.07  \n",
      "LabelPropagation                   0.54  \n",
      "LabelSpreading                     0.94  \n",
      "PassiveAggressiveClassifier        0.01  \n",
      "CalibratedClassifierCV             0.03  \n",
      "\n",
      "================================================================================\n",
      "MODELOS SELECCIONADOS PARA FASE 2 (GridSearchCV)\n",
      "================================================================================\n",
      "\n",
      "Total modelos a optimizar: 9\n",
      "\n",
      "De LazyPredict (Top 5):\n",
      "1. LGBMClassifier - F1: 0.8650 | Accuracy: 0.9069\n",
      "2. LabelPropagation - F1: 0.8632 | Accuracy: 0.9056\n",
      "3. LabelSpreading - F1: 0.8632 | Accuracy: 0.9056\n",
      "4. PassiveAggressiveClassifier - F1: 0.8626 | Accuracy: 0.9069\n",
      "5. CalibratedClassifierCV - F1: 0.8626 | Accuracy: 0.9069\n",
      "\n",
      "Modelos adicionales solicitados:\n",
      "  ‚Ä¢ NearestCentroid - F1: 0.7791 | Accuracy: 0.7331\n",
      "  ‚Ä¢ LogisticRegression - F1: 0.8626 | Accuracy: 0.9069\n",
      "  ‚Ä¢ XGBClassifier - F1: 0.8588 | Accuracy: 0.8994\n",
      "  ‚Ä¢ RandomForestClassifier - F1: 0.8550 | Accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "# Top 5 modelos + modelos adicionales solicitados\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 5 MODELOS POR F1-SCORE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "top_5_models = models.nlargest(5, 'F1 Score')\n",
    "print(top_5_models)\n",
    "\n",
    "# Agregar modelos adicionales solicitados expl√≠citamente\n",
    "modelos_adicionales = ['NearestCentroid', 'LogisticRegression', 'XGBClassifier', 'RandomForestClassifier']\n",
    "modelos_para_optimizar = list(set(list(top_5_models.index) + modelos_adicionales))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODELOS SELECCIONADOS PARA FASE 2 (GridSearchCV)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal modelos a optimizar: {len(modelos_para_optimizar)}\")\n",
    "print(\"\\nDe LazyPredict (Top 5):\")\n",
    "for i, model_name in enumerate(top_5_models.index, 1):\n",
    "    f1 = top_5_models.loc[model_name, 'F1 Score']\n",
    "    acc = top_5_models.loc[model_name, 'Accuracy']\n",
    "    print(f\"{i}. {model_name} - F1: {f1:.4f} | Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nModelos adicionales solicitados:\")\n",
    "for model_name in modelos_adicionales:\n",
    "    if model_name in models.index:\n",
    "        f1 = models.loc[model_name, 'F1 Score']\n",
    "        acc = models.loc[model_name, 'Accuracy']\n",
    "        print(f\"  ‚Ä¢ {model_name} - F1: {f1:.4f} | Accuracy: {acc:.4f}\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ {model_name} - (no evaluado en LazyPredict)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ej2uj3b29hv",
   "metadata": {},
   "source": [
    "---\n",
    "## FASE 2: Optimizaci√≥n de Hiperpar√°metros con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e0cxenai3y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Funciones de evaluaci√≥n definidas\n"
     ]
    }
   ],
   "source": [
    "# Funciones de evaluaci√≥n\n",
    "def gini_coefficient(y_true, y_pred_proba):\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    return 2 * auc - 1\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_proba, metric='f1'):\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        if metric == 'f1':\n",
    "            score = f1_score(y_true, y_pred)\n",
    "        elif metric == 'precision':\n",
    "            score = precision_score(y_true, y_pred, zero_division=0)\n",
    "        elif metric == 'recall':\n",
    "            score = recall_score(y_true, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    optimal_idx = np.argmax(scores)\n",
    "    return thresholds[optimal_idx], scores[optimal_idx]\n",
    "\n",
    "print(\"‚úì Funciones de evaluaci√≥n definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f9a3vj6ips",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modelos adicionales importados\n"
     ]
    }
   ],
   "source": [
    "# Importar modelos adicionales\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "print(\"‚úì Modelos adicionales importados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ttusi9t48gr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Grillas OPTIMIZADAS con par√°metros de regularizaci√≥n/suavizado:\n",
      "\n",
      "üìä Combinaciones por modelo:\n",
      "  - LogisticRegression: 4√ó2√ó2 = 16 combinaciones √ó 5 folds = 80 fits\n",
      "  - SVC: 3√ó2√ó2√ó2 = 24 combinaciones √ó 5 folds = 120 fits\n",
      "  - NearestCentroid: 2√ó4 = 8 combinaciones √ó 5 folds = 40 fits\n",
      "  - Perceptron: 3√ó3√ó2 = 18 combinaciones √ó 5 folds = 90 fits\n",
      "  - LGBMClassifier: 2√ó2√ó2√ó2√ó2√ó2√ó1√ó2 = 256 combinaciones √ó 5 folds = 1,280 fits ‚ö°\n",
      "  - ExtraTreesClassifier: 2√ó3√ó2√ó2√ó1√ó2√ó2√ó1 = 192 combinaciones √ó 5 folds = 960 fits ‚ö°\n",
      "  - RandomForestClassifier: 2√ó3√ó2√ó2√ó1√ó2√ó2 = 192 combinaciones √ó 5 folds = 960 fits ‚ö°\n",
      "\n",
      "üìà Total modelos a optimizar: 7\n",
      "\n",
      "‚ö° Grillas SIGNIFICATIVAMENTE reducidas para mejor rendimiento\n"
     ]
    }
   ],
   "source": [
    "# Grillas de hiperpar√°metros con par√°metros de suavizado/regularizaci√≥n (OPTIMIZADAS)\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],  # Inverso de fuerza de regularizaci√≥n\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear'],  # Compatible con l1 y l2\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': [1000]\n",
    "    },\n",
    "    \n",
    "    'SVC': {\n",
    "        'C': [0.1, 1.0, 10.0],  # Regularizaci√≥n\n",
    "        'kernel': ['linear', 'rbf'],  # Solo los m√°s comunes\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'class_weight': ['balanced', None],\n",
    "        'probability': [True],  # Necesario para predict_proba\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'NearestCentroid': {\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'shrink_threshold': [None, 0.5, 1.0, 2.0]\n",
    "    },\n",
    "    \n",
    "    'Perceptron': {\n",
    "        'penalty': ['l2', 'l1', None],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': [1000],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'LGBMClassifier': {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [15, 31],\n",
    "        'max_depth': [3, 5],  # Reducido de 3 a 2\n",
    "        'n_estimators': [50, 100],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1],  # L1 regularization\n",
    "        'reg_lambda': [1.0],  # L2 regularization (fijo)\n",
    "        'class_weight': ['balanced', None],\n",
    "        'random_state': [42],\n",
    "        'verbose': [-1]\n",
    "    },\n",
    "    \n",
    "    'ExtraTreesClassifier': {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5, None],  # Reducido de 4 a 3\n",
    "        'min_samples_split': [10, 20],\n",
    "        'min_samples_leaf': [5, 10],\n",
    "        'max_features': ['sqrt'],  # Solo sqrt (reducido de 2 a 1)\n",
    "        'class_weight': ['balanced', None],\n",
    "        'ccp_alpha': [0.0, 0.01],\n",
    "        'bootstrap': [True],  # Solo True (reducido de 2 a 1)\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5, None],  # Reducido de 4 a 3\n",
    "        'min_samples_split': [10, 20],\n",
    "        'min_samples_leaf': [5, 10],\n",
    "        'max_features': ['sqrt'],  # Solo sqrt (reducido de 2 a 1)\n",
    "        'class_weight': ['balanced', None],\n",
    "        'ccp_alpha': [0.0, 0.01],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_mapping = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'NearestCentroid': NearestCentroid(),\n",
    "    'Perceptron': Perceptron(random_state=42),\n",
    "    'LGBMClassifier': LGBMClassifier(random_state=42, verbose=-1),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(random_state=42),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "modelos_para_optimizar = list(model_mapping.keys())\n",
    "\n",
    "print(\"‚úì Grillas OPTIMIZADAS con par√°metros de regularizaci√≥n/suavizado:\")\n",
    "print(\"\\nüìä Combinaciones por modelo:\")\n",
    "print(\"  - LogisticRegression: 4√ó2√ó2 = 16 combinaciones √ó 5 folds = 80 fits\")\n",
    "print(\"  - SVC: 3√ó2√ó2√ó2 = 24 combinaciones √ó 5 folds = 120 fits\")\n",
    "print(\"  - NearestCentroid: 2√ó4 = 8 combinaciones √ó 5 folds = 40 fits\")\n",
    "print(\"  - Perceptron: 3√ó3√ó2 = 18 combinaciones √ó 5 folds = 90 fits\")\n",
    "print(\"  - LGBMClassifier: 2√ó2√ó2√ó2√ó2√ó2√ó1√ó2 = 256 combinaciones √ó 5 folds = 1,280 fits ‚ö°\")\n",
    "print(\"  - ExtraTreesClassifier: 2√ó3√ó2√ó2√ó1√ó2√ó2√ó1 = 192 combinaciones √ó 5 folds = 960 fits ‚ö°\")\n",
    "print(\"  - RandomForestClassifier: 2√ó3√ó2√ó2√ó1√ó2√ó2 = 192 combinaciones √ó 5 folds = 960 fits ‚ö°\")\n",
    "print(f\"\\nüìà Total modelos a optimizar: {len(modelos_para_optimizar)}\")\n",
    "print(\"\\n‚ö° Grillas SIGNIFICATIVAMENTE reducidas para mejor rendimiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "w78k2y5xngm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID SEARCH CON VALIDACI√ìN CRUZADA\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "[1/7] Optimizando: LogisticRegression\n",
      "================================================================================\n",
      "Combinaciones: 16 | Total fits: 80\n",
      "‚úì F1-Score CV: 0.2198\n",
      "Mejores par√°metros: {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "================================================================================\n",
      "[2/7] Optimizando: SVC\n",
      "================================================================================\n",
      "Combinaciones: 24 | Total fits: 120\n",
      "‚úì F1-Score CV: 0.2278\n",
      "Mejores par√°metros: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear', 'probability': True, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "[3/7] Optimizando: NearestCentroid\n",
      "================================================================================\n",
      "Combinaciones: 8 | Total fits: 40\n",
      "‚úì F1-Score CV: 0.2278\n",
      "Mejores par√°metros: {'metric': 'euclidean', 'shrink_threshold': 2.0}\n",
      "\n",
      "================================================================================\n",
      "[4/7] Optimizando: Perceptron\n",
      "================================================================================\n",
      "Combinaciones: 18 | Total fits: 90\n",
      "‚úì F1-Score CV: 0.1617\n",
      "Mejores par√°metros: {'alpha': 0.0001, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "[5/7] Optimizando: LGBMClassifier\n",
      "================================================================================\n",
      "Combinaciones: 128 | Total fits: 640\n",
      "‚úì F1-Score CV: 0.2171\n",
      "Mejores par√°metros: {'class_weight': 'balanced', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'num_leaves': 15, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1.0, 'subsample': 0.8, 'verbose': -1}\n",
      "\n",
      "================================================================================\n",
      "[6/7] Optimizando: ExtraTreesClassifier\n",
      "================================================================================\n",
      "Combinaciones: 96 | Total fits: 480\n",
      "‚úì F1-Score CV: 0.2278\n",
      "Mejores par√°metros: {'bootstrap': True, 'ccp_alpha': 0.01, 'class_weight': 'balanced', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "[7/7] Optimizando: RandomForestClassifier\n",
      "================================================================================\n",
      "Combinaciones: 96 | Total fits: 480\n",
      "‚úì F1-Score CV: 0.2278\n",
      "Mejores par√°metros: {'ccp_alpha': 0.01, 'class_weight': 'balanced', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50, 'random_state': 42}\n",
      "\n",
      "================================================================================\n",
      "Completado: 7/7 modelos\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "print(\"=\" * 80)\n",
    "print(\"GRID SEARCH CON VALIDACI√ìN CRUZADA\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "optimized_models = {}\n",
    "grid_results = {}\n",
    "\n",
    "for i, model_name in enumerate(modelos_para_optimizar, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"[{i}/{len(modelos_para_optimizar)}] Optimizando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if model_name not in param_grids or model_name not in model_mapping:\n",
    "        print(f\"‚ö† No hay grilla para {model_name}, saltando...\")\n",
    "        continue\n",
    "    \n",
    "    base_model = model_mapping[model_name]\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    n_combinations = np.prod([len(v) if isinstance(v, list) else 1 for v in param_grid.values()])\n",
    "    print(f\"Combinaciones: {int(n_combinations)} | Total fits: {int(5 * n_combinations)}\")\n",
    "    \n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=f1_scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_selected, y_train)\n",
    "        \n",
    "        optimized_models[model_name] = grid_search.best_estimator_\n",
    "        grid_results[model_name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score_cv': grid_search.best_score_\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì F1-Score CV: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Mejores par√°metros: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Completado: {len(optimized_models)}/{len(modelos_para_optimizar)} modelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ziv4qbyg6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACI√ìN EN TEST SET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Evaluando: LogisticRegression\n",
      "================================================================================\n",
      "Threshold: 0.580\n",
      "F1 (CV): 0.2198 | F1 (Test): 0.1995\n",
      "Accuracy: 0.7844 | Precision: 0.1525 | Recall: 0.2886\n",
      "AUC: 0.5416 | Gini: 0.0832\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN: 1212 | FP:  239\n",
      "  FN:  106 | TP:   43\n",
      "\n",
      "================================================================================\n",
      "Evaluando: SVC\n",
      "================================================================================\n",
      "Threshold: 0.100\n",
      "F1 (CV): 0.2278 | F1 (Test): 0.1882\n",
      "Accuracy: 0.7681 | Precision: 0.1396 | Recall: 0.2886\n",
      "AUC: 0.5028 | Gini: 0.0055\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN: 1186 | FP:  265\n",
      "  FN:  106 | TP:   43\n",
      "\n",
      "================================================================================\n",
      "Evaluando: NearestCentroid\n",
      "================================================================================\n",
      "Threshold: 0.430\n",
      "F1 (CV): 0.2278 | F1 (Test): 0.1882\n",
      "Accuracy: 0.7681 | Precision: 0.1396 | Recall: 0.2886\n",
      "AUC: 0.5336 | Gini: 0.0672\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN: 1186 | FP:  265\n",
      "  FN:  106 | TP:   43\n",
      "\n",
      "================================================================================\n",
      "Evaluando: Perceptron\n",
      "================================================================================\n",
      "Threshold: 0.740\n",
      "F1 (CV): 0.1617 | F1 (Test): 0.1786\n",
      "Accuracy: 0.4713 | Precision: 0.1044 | Recall: 0.6174\n",
      "AUC: 0.5221 | Gini: 0.0443\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN:  662 | FP:  789\n",
      "  FN:   57 | TP:   92\n",
      "\n",
      "================================================================================\n",
      "Evaluando: LGBMClassifier\n",
      "================================================================================\n",
      "Threshold: 0.500\n",
      "F1 (CV): 0.2171 | F1 (Test): 0.1977\n",
      "Accuracy: 0.7819 | Precision: 0.1503 | Recall: 0.2886\n",
      "AUC: 0.5484 | Gini: 0.0968\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN: 1208 | FP:  243\n",
      "  FN:  106 | TP:   43\n",
      "\n",
      "================================================================================\n",
      "Evaluando: ExtraTreesClassifier\n",
      "================================================================================\n",
      "Threshold: 0.550\n",
      "F1 (CV): 0.2278 | F1 (Test): 0.1929\n",
      "Accuracy: 0.7856 | Precision: 0.1486 | Recall: 0.2752\n",
      "AUC: 0.5211 | Gini: 0.0422\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN: 1216 | FP:  235\n",
      "  FN:  108 | TP:   41\n",
      "\n",
      "================================================================================\n",
      "Evaluando: RandomForestClassifier\n",
      "================================================================================\n",
      "Threshold: 0.560\n",
      "F1 (CV): 0.2278 | F1 (Test): 0.1929\n",
      "Accuracy: 0.7856 | Precision: 0.1486 | Recall: 0.2752\n",
      "AUC: 0.5289 | Gini: 0.0577\n",
      "\n",
      "Matriz de Confusi√≥n:\n",
      "  TN: 1216 | FP:  235\n",
      "  FN:  108 | TP:   41\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "                Modelo  F1_CV  F1_Test  Accuracy  Precision  Recall  AUC  Gini  Threshold\n",
      "    LogisticRegression   0.22     0.20      0.78       0.15    0.29 0.54  0.08       0.58\n",
      "        LGBMClassifier   0.22     0.20      0.78       0.15    0.29 0.55  0.10       0.50\n",
      "  ExtraTreesClassifier   0.23     0.19      0.79       0.15    0.28 0.52  0.04       0.55\n",
      "RandomForestClassifier   0.23     0.19      0.79       0.15    0.28 0.53  0.06       0.56\n",
      "                   SVC   0.23     0.19      0.77       0.14    0.29 0.50  0.01       0.10\n",
      "       NearestCentroid   0.23     0.19      0.77       0.14    0.29 0.53  0.07       0.43\n",
      "            Perceptron   0.16     0.18      0.47       0.10    0.62 0.52  0.04       0.74\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n en test set\n",
    "print(\"=\" * 80)\n",
    "print(\"EVALUACI√ìN EN TEST SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for model_name, model in optimized_models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_pred_proba = model.decision_function(X_test_selected)\n",
    "        y_pred_proba = (y_pred_proba - y_pred_proba.min()) / (y_pred_proba.max() - y_pred_proba.min())\n",
    "    else:\n",
    "        y_pred_proba = model.predict(X_test_selected).astype(float)\n",
    "    \n",
    "    optimal_threshold, _ = find_optimal_threshold(y_test, y_pred_proba)\n",
    "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred_optimal)\n",
    "    precision = precision_score(y_test, y_pred_optimal, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_optimal, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_optimal, zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        gini = gini_coefficient(y_test, y_pred_proba)\n",
    "    except:\n",
    "        auc = gini = np.nan\n",
    "    \n",
    "    test_results.append({\n",
    "        'Modelo': model_name,\n",
    "        'F1_CV': grid_results[model_name]['best_score_cv'],\n",
    "        'F1_Test': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'AUC': auc,\n",
    "        'Gini': gini,\n",
    "        'Threshold': optimal_threshold\n",
    "    })\n",
    "    \n",
    "    print(f\"Threshold: {optimal_threshold:.3f}\")\n",
    "    print(f\"F1 (CV): {grid_results[model_name]['best_score_cv']:.4f} | F1 (Test): {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f} | Gini: {gini:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "    print(f\"\\nMatriz de Confusi√≥n:\")\n",
    "    print(f\"  TN: {cm[0,0]:4d} | FP: {cm[0,1]:4d}\")\n",
    "    print(f\"  FN: {cm[1,0]:4d} | TP: {cm[1,1]:4d}\")\n",
    "\n",
    "df_results = pd.DataFrame(test_results).sort_values('F1_Test', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESUMEN DE RESULTADOS\")\n",
    "print(f\"{'='*80}\")\n",
    "print()\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ggq61o9bca",
   "metadata": {},
   "source": [
    "---\n",
    "## Exportaci√≥n LGBMClassifier con Dataset Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "u2yw7nzqyi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REENTRENAMIENTO LGBM CON DATASET COMPLETO\n",
      "================================================================================\n",
      "\n",
      "Dataset completo: (7999, 6)\n",
      "Siniestrados totales: 743 (9.29%)\n",
      "\n",
      "Mejores par√°metros del LGBMClassifier:\n",
      "  class_weight: balanced\n",
      "  learning_rate: 0.01\n",
      "  max_depth: 3\n",
      "  n_estimators: 50\n",
      "  num_leaves: 15\n",
      "  random_state: 42\n",
      "  reg_alpha: 0\n",
      "  reg_lambda: 1.0\n",
      "  subsample: 0.8\n",
      "  verbose: -1\n",
      "\n",
      "‚úì LGBMClassifier reentrenado con 7999 registros\n",
      "‚úì Listo para exportar\n"
     ]
    }
   ],
   "source": [
    "# Reentrenar LGBMClassifier con TODO el dataset usando mejores hiperpar√°metros\n",
    "print(\"=\" * 80)\n",
    "print(\"REENTRENAMIENTO LGBM CON DATASET COMPLETO\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Combinar train y test\n",
    "X_full = pd.concat([X_train_selected, X_test_selected])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "print(f\"Dataset completo: {X_full.shape}\")\n",
    "print(f\"Siniestrados totales: {y_full.sum()} ({y_full.mean()*100:.2f}%)\")\n",
    "\n",
    "# Obtener los mejores par√°metros del LGBMClassifier\n",
    "best_params_lgbm = grid_results['LGBMClassifier']['best_params']\n",
    "print(f\"\\nMejores par√°metros del LGBMClassifier:\")\n",
    "for param, value in best_params_lgbm.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Crear y entrenar modelo con todos los datos\n",
    "lgbm_final = LGBMClassifier(**best_params_lgbm)\n",
    "lgbm_final.fit(X_full, y_full)\n",
    "\n",
    "print(f\"\\n‚úì LGBMClassifier reentrenado con {len(X_full)} registros\")\n",
    "print(f\"‚úì Listo para exportar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "xkuwlk0wx4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELO LGBM EXPORTADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "Ruta: ../models/clasificacion_contenidos.pkl\n",
      "\n",
      "Modelo: LGBMClassifier\n",
      "Mejores par√°metros: {'class_weight': 'balanced', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'num_leaves': 15, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1.0, 'subsample': 0.8, 'verbose': -1}\n",
      "\n",
      "M√©tricas en Test Set:\n",
      "  F1-Score:  0.1977\n",
      "  Accuracy:  0.7819\n",
      "  Precision: 0.1503\n",
      "  Recall:    0.2886\n",
      "  AUC-ROC:   0.5484\n",
      "  Gini:      0.0968\n",
      "\n",
      "Threshold √≥ptimo: 0.500\n",
      "\n",
      "Contenido del archivo:\n",
      "  ‚Ä¢ modelo: LGBMClassifier entrenado con 7999 registros\n",
      "  ‚Ä¢ preprocessor: ColumnTransformer (StandardScaler + OneHotEncoder)\n",
      "  ‚Ä¢ features_seleccionadas: ['2_o_mas_inquilinos_Si', 'a√±o_cursado_2do a√±o', 'a√±o_cursado_3er a√±o', 'a√±o_cursado_4to a√±o', 'a√±o_cursado_posgrado', 'distancia_al_campus']\n",
      "  ‚Ä¢ threshold_optimo: 0.500\n",
      "  ‚Ä¢ metricas: diccionario con todas las m√©tricas\n",
      "  ‚Ä¢ mejores_parametros: {'class_weight': 'balanced', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'num_leaves': 15, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1.0, 'subsample': 0.8, 'verbose': -1}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Crear directorio models si no existe\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Preparar objeto para exportar\n",
    "modelo_export = {\n",
    "    'modelo': lgbm_final,\n",
    "    'preprocessor': preprocessor,\n",
    "    'features_seleccionadas': final_selected_features,\n",
    "    'threshold_optimo': df_results[df_results['Modelo'] == 'LGBMClassifier']['Threshold'].values[0],\n",
    "    'metricas': {\n",
    "        'F1_CV': grid_results['LGBMClassifier']['best_score_cv'],\n",
    "        'F1_Test': df_results[df_results['Modelo'] == 'LGBMClassifier']['F1_Test'].values[0],\n",
    "        'Accuracy': df_results[df_results['Modelo'] == 'LGBMClassifier']['Accuracy'].values[0],\n",
    "        'Precision': df_results[df_results['Modelo'] == 'LGBMClassifier']['Precision'].values[0],\n",
    "        'Recall': df_results[df_results['Modelo'] == 'LGBMClassifier']['Recall'].values[0],\n",
    "        'AUC': df_results[df_results['Modelo'] == 'LGBMClassifier']['AUC'].values[0],\n",
    "        'Gini': df_results[df_results['Modelo'] == 'LGBMClassifier']['Gini'].values[0]\n",
    "    },\n",
    "    'mejores_parametros': grid_results['LGBMClassifier']['best_params']\n",
    "}\n",
    "\n",
    "# Exportar modelo\n",
    "model_path = '../models/clasificacion_contenidos.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(modelo_export, f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELO LGBM EXPORTADO EXITOSAMENTE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nRuta: {model_path}\")\n",
    "print(f\"\\nModelo: LGBMClassifier\")\n",
    "print(f\"Mejores par√°metros: {modelo_export['mejores_parametros']}\")\n",
    "print(f\"\\nM√©tricas en Test Set:\")\n",
    "print(f\"  F1-Score:  {modelo_export['metricas']['F1_Test']:.4f}\")\n",
    "print(f\"  Accuracy:  {modelo_export['metricas']['Accuracy']:.4f}\")\n",
    "print(f\"  Precision: {modelo_export['metricas']['Precision']:.4f}\")\n",
    "print(f\"  Recall:    {modelo_export['metricas']['Recall']:.4f}\")\n",
    "print(f\"  AUC-ROC:   {modelo_export['metricas']['AUC']:.4f}\")\n",
    "print(f\"  Gini:      {modelo_export['metricas']['Gini']:.4f}\")\n",
    "print(f\"\\nThreshold √≥ptimo: {modelo_export['threshold_optimo']:.3f}\")\n",
    "print(f\"\\nContenido del archivo:\")\n",
    "print(f\"  ‚Ä¢ modelo: LGBMClassifier entrenado con {len(X_full)} registros\")\n",
    "print(f\"  ‚Ä¢ preprocessor: ColumnTransformer (StandardScaler + OneHotEncoder)\")\n",
    "print(f\"  ‚Ä¢ features_seleccionadas: {final_selected_features}\")\n",
    "print(f\"  ‚Ä¢ threshold_optimo: {modelo_export['threshold_optimo']:.3f}\")\n",
    "print(f\"  ‚Ä¢ metricas: diccionario con todas las m√©tricas\")\n",
    "print(f\"  ‚Ä¢ mejores_parametros: {modelo_export['mejores_parametros']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competencia_cas_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
